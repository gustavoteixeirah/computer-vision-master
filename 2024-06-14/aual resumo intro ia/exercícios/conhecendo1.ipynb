{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "ü§ó Transformadores\n",
        "Aprendizado de m√°quina de √∫ltima gera√ß√£o para PyTorch, TensorFlow e JAX.\n",
        "\n",
        "ü§ó Transformers fornece APIs e ferramentas para baixar e treinar facilmente modelos pr√©-treinados de √∫ltima gera√ß√£o. O uso de modelos pr√©-treinados pode reduzir os custos de computa√ß√£o, a pegada de carbono e economizar tempo e recursos necess√°rios para treinar um modelo do zero. Esses modelos suportam tarefas comuns em diferentes modalidades, como:\n",
        "\n",
        "üìù Processamento de linguagem natural: classifica√ß√£o de texto, reconhecimento de entidade nomeada, resposta a perguntas, modelagem de linguagem, resumo, tradu√ß√£o, m√∫ltipla escolha e gera√ß√£o de texto.\n",
        "üñºÔ∏è Vis√£o Computacional: classifica√ß√£o de imagens, detec√ß√£o de objetos e segmenta√ß√£o.\n",
        "üó£Ô∏è √Åudio: reconhecimento autom√°tico de fala e classifica√ß√£o de √°udio.\n",
        "üêô Multimodal: resposta a perguntas em tabelas, reconhecimento √≥ptico de caracteres, extra√ß√£o de informa√ß√µes de documentos digitalizados, classifica√ß√£o de v√≠deos e resposta visual a perguntas.\n",
        "\n",
        "ü§ó Os transformadores suportam interoperabilidade de estrutura entre PyTorch, TensorFlow e JAX. Isto proporciona flexibilidade para utilizar uma estrutura diferente em cada fase da vida de um modelo; treinar um modelo em tr√™s linhas de c√≥digo em uma estrutura e carreg√°-lo para infer√™ncia em outra. Os modelos tamb√©m podem ser exportados para um formato como ONNX e TorchScript para implanta√ß√£o em ambientes de produ√ß√£o."
      ],
      "metadata": {
        "id": "qrMaTBpUwm6E"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gYL7GFVOsOYz"
      },
      "outputs": [],
      "source": [
        "\n",
        "! pip install transformers datasets\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r4m9AofzsOY1"
      },
      "source": [
        "# Rapido tour"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mrd7FH_9sOY2"
      },
      "source": [
        "Comece a trabalhar com ü§ó Transformers! Seja voc√™ um desenvolvedor ou um usu√°rio comum, este tour r√°pido ajudar√° voc√™ a come√ßar e mostrar√° como usar o [pipeline()](https://huggingface.co/docs/transformers/main/en/main_classes/ pipelines#transformers.pipeline) para infer√™ncia, carregue um modelo pr√©-treinado e um pr√©-processador com uma [AutoClass](https://huggingface.co/docs/transformers/main/en/./model_doc/auto) e treine rapidamente um modelo com PyTorch ou TensorFlow.\n",
        "\n",
        "\n",
        "Antes de come√ßar, certifique-se de ter todas as bibliotecas necess√°rias instaladas:\n",
        "\n",
        "```bash\n",
        "!pip instala conjuntos de dados de transformadores\n",
        "```\n",
        "\n",
        "Voc√™ tamb√©m precisar√° instalar sua estrutura de aprendizado de m√°quina preferida:\n",
        "\n",
        "```bash\n",
        "pip instalar tensorflow\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G8mNrtbPsOY2"
      },
      "source": [
        "## Pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6jPGpK9MsOY3"
      },
      "source": [
        "O [pipeline()](https://huggingface.co/docs/transformers/main/en/main_classes/pipelines#transformers.pipeline) √© a maneira mais f√°cil e r√°pida de usar um modelo pr√©-treinado para infer√™ncia. Voc√™ pode usar o [pipeline()](https://huggingface.co/docs/transformers/main/en/main_classes/pipelines#transformers.pipeline) pronto para uso para muitas tarefas em diferentes modalidades, algumas das quais que s√£o mostrados na tabela abaixo:\n",
        "\n",
        "<Dica>\n",
        "\n",
        "Para obter uma lista completa de tarefas dispon√≠veis, confira a [refer√™ncia da API do pipeline](https://huggingface.co/docs/transformers/main/en/./main_classes/pipelines).\n",
        "\n",
        "</Tip>\n",
        "\n",
        "| **Task**                     | **Description**                                                                                              | **Modality**    | **Pipeline identifier**                       |\n",
        "|------------------------------|--------------------------------------------------------------------------------------------------------------|-----------------|-----------------------------------------------|\n",
        "| Text classification          | assign a label to a given sequence of text                                                                   | NLP             | pipeline(task=‚Äúsentiment-analysis‚Äù)           |\n",
        "| Text generation              | generate text given a prompt                                                                                 | NLP             | pipeline(task=‚Äútext-generation‚Äù)              |\n",
        "| Summarization                | generate a summary of a sequence of text or document                                                         | NLP             | pipeline(task=‚Äúsummarization‚Äù)                |\n",
        "| Image classification         | assign a label to an image                                                                                   | Computer vision | pipeline(task=‚Äúimage-classification‚Äù)         |\n",
        "| Image segmentation           | assign a label to each individual pixel of an image (supports semantic, panoptic, and instance segmentation) | Computer vision | pipeline(task=‚Äúimage-segmentation‚Äù)           |\n",
        "| Object detection             | predict the bounding boxes and classes of objects in an image                                                | Computer vision | pipeline(task=‚Äúobject-detection‚Äù)             |\n",
        "| Audio classification         | assign a label to some audio data                                                                            | Audio           | pipeline(task=‚Äúaudio-classification‚Äù)         |\n",
        "| Automatic speech recognition | transcribe speech into text                                                                                  | Audio           | pipeline(task=‚Äúautomatic-speech-recognition‚Äù) |\n",
        "| Visual question answering    | answer a question about the image, given an image and a question                                             | Multimodal      | pipeline(task=‚Äúvqa‚Äù)                          |\n",
        "| Document question answering  | answer a question about a document, given an image and a question                                            | Multimodal      | pipeline(task=\"document-question-answering\")  |\n",
        "| Image captioning             | generate a caption for a given image                                                                         | Multimodal      | pipeline(task=\"image-to-text\")                |\n",
        "\n",
        "Comece criando uma inst√¢ncia de [pipeline()](https://huggingface.co/docs/transformers/main/en/main_classes/pipelines#transformers.pipeline) e especificando uma tarefa para a qual deseja us√°-lo. Neste guia, voc√™ usar√° o [pipeline()](https://huggingface.co/docs/transformers/main/en/main_classes/pipelines#transformers.pipeline) para an√°lise de sentimento como exemplo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NvYVKHCxsOY3"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "classifier = pipeline(\"sentiment-analysis\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hZOeY5HesOY4"
      },
      "source": [
        "O [pipeline()](https://huggingface.co/docs/transformers/main/en/main_classes/pipelines#transformers.pipeline) baixa e armazena em cache um [modelo pr√©-treinado](https://huggingface.co/distilbert) padr√£o -base-uncased-finetuned-sst-2-english) e tokenizer para an√°lise de sentimento. Agora voc√™ pode usar o `classificador` no seu texto de destino:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oVOwycyPsOY4",
        "outputId": "ea2a856c-4565-4e51-dae9-0ea0473b7b02"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'label': 'POSITIVE', 'score': 0.9998}]"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "classifier(\"We are very happy to show you the ü§ó Transformers library.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dXg_XQQVsOY4"
      },
      "source": [
        "Se voc√™ tiver mais de uma entrada, passe suas entradas como uma lista para [pipeline()](https://huggingface.co/docs/transformers/main/en/main_classes/pipelines#transformers.pipeline) para retornar uma lista de dicion√°rios:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Km1yYcDpsOY4",
        "outputId": "726c2bb5-3e56-41b4-d3f5-e984b894e23b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "label: POSITIVE, with score: 0.9998\n",
              "label: NEGATIVE, with score: 0.5309"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "results = classifier([\"We are very happy to show you the ü§ó Transformers library.\", \"We hope you don't hate it.\"])\n",
        "for result in results:\n",
        "    print(f\"label: {result['label']}, with score: {round(result['score'], 4)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lQA38kwxsOY5"
      },
      "source": [
        "O [pipeline()](https://huggingface.co/docs/transformers/main/en/main_classes/pipelines#transformers.pipeline) tamb√©m pode iterar em um conjunto de dados inteiro para qualquer tarefa que voc√™ desejar. Para este exemplo, vamos escolher o reconhecimento autom√°tico de fala como nossa tarefa:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5XgYXHUMsOY5"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import pipeline\n",
        "\n",
        "speech_recognizer = pipeline(\"automatic-speech-recognition\", model=\"facebook/wav2vec2-base-960h\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ulPFp3bosOY5"
      },
      "source": [
        "Carregue um conjunto de dados de √°udio (consulte ü§ó Conjuntos de dados [In√≠cio r√°pido](https://huggingface.co/docs/datasets/quickstart#audio) para obter mais detalhes) que voc√™ gostaria de iterar. Por exemplo, carregue o conjunto de dados [MInDS-14](https://huggingface.co/datasets/PolyAI/minds14):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "htZG_OtvsOY5"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset, Audio\n",
        "\n",
        "dataset = load_dataset(\"PolyAI/minds14\", name=\"en-US\", split=\"train\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JeVr0kBasOY5"
      },
      "source": [
        "Voc√™ precisa ter certeza de que a taxa de amostragem do conjunto de dados corresponde √† amostragem\n",
        "rate [`facebook/wav2vec2-base-960h`](https://huggingface.co/facebook/wav2vec2-base-960h) foi treinado em:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JIpV6SsxsOY5"
      },
      "outputs": [],
      "source": [
        "dataset = dataset.cast_column(\"audio\", Audio(sampling_rate=speech_recognizer.feature_extractor.sampling_rate))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mEHHpbwhsOY5"
      },
      "source": [
        "Voc√™ precisa ter certeza de que a taxa de amostragem do conjunto de dados corresponde √† amostragem\n",
        "rate [`facebook/wav2vec2-base-960h`](https://huggingface.co/facebook/wav2vec2-base-960h) foi treinado em:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2LExbGUOsOY5",
        "outputId": "5c3802c3-13b0-499c-8ed8-24535d9619d7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['I WOULD LIKE TO SET UP A JOINT ACCOUNT WITH MY PARTNER HOW DO I PROCEED WITH DOING THAT', \"FONDERING HOW I'D SET UP A JOIN TO HELL T WITH MY WIFE AND WHERE THE AP MIGHT BE\", \"I I'D LIKE TOY SET UP A JOINT ACCOUNT WITH MY PARTNER I'M NOT SEEING THE OPTION TO DO IT ON THE APSO I CALLED IN TO GET SOME HELP CAN I JUST DO IT OVER THE PHONE WITH YOU AND GIVE YOU THE INFORMATION OR SHOULD I DO IT IN THE AP AN I'M MISSING SOMETHING UQUETTE HAD PREFERRED TO JUST DO IT OVER THE PHONE OF POSSIBLE THINGS\", 'HOW DO I FURN A JOINA COUT']"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "result = speech_recognizer(dataset[:4][\"audio\"])\n",
        "print([d[\"text\"] for d in result])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}