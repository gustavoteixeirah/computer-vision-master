{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-07-19T21:04:26.114622Z",
          "iopub.status.busy": "2024-07-19T21:04:26.114060Z",
          "iopub.status.idle": "2024-07-19T21:04:26.121986Z",
          "shell.execute_reply": "2024-07-19T21:04:26.120719Z",
          "shell.execute_reply.started": "2024-07-19T21:04:26.114540Z"
        },
        "id": "rsCahO1FoD-2",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-07-19T21:04:26.124035Z",
          "iopub.status.busy": "2024-07-19T21:04:26.123537Z",
          "iopub.status.idle": "2024-07-19T21:04:26.139271Z",
          "shell.execute_reply": "2024-07-19T21:04:26.138091Z",
          "shell.execute_reply.started": "2024-07-19T21:04:26.123999Z"
        },
        "id": "ovNRTRU-oD-2",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Função para carregar imagens de um diretório e redimensionar\n",
        "def load_images_from_folder(folder, img_size, labels_dict=None, max_images=None, sort=False):\n",
        "    images = []\n",
        "    labels = []\n",
        "\n",
        "    file_list = os.listdir(folder)\n",
        "    # Ordenar os arquivos numericamente (por conta do submission file)\n",
        "    if sort:\n",
        "        file_list = sorted(file_list, key=lambda x: int(x.split('.')[0]))\n",
        "    \n",
        "    max_images = len(file_list) // 4\n",
        "\n",
        "    for filename in file_list:\n",
        "        if len(images) >= max_images:\n",
        "            break\n",
        "        if max_images and len(images) >= max_images:\n",
        "            break\n",
        "        if filename.endswith(\".jpg\"):\n",
        "            img_path = os.path.join(folder, filename)\n",
        "            img = Image.open(img_path).resize((img_size, img_size)).convert('RGB')\n",
        "            img_array = np.array(img)\n",
        "            images.append(img_array)\n",
        "            # Etiquetar as imagens: 0 para gato, 1 para cachorro\n",
        "            if labels_dict:\n",
        "                labels.append(labels_dict[filename])\n",
        "            elif 'cat' in filename:\n",
        "                labels.append('cat')\n",
        "            elif 'dog' in filename:\n",
        "                labels.append('dog')\n",
        "    return np.array(images), np.array(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-07-19T21:04:26.142863Z",
          "iopub.status.busy": "2024-07-19T21:04:26.142396Z",
          "iopub.status.idle": "2024-07-19T21:08:36.421731Z",
          "shell.execute_reply": "2024-07-19T21:08:36.420396Z",
          "shell.execute_reply.started": "2024-07-19T21:04:26.142816Z"
        },
        "id": "YK8JoSgwoD-3",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "train_folder = './train'\n",
        "submission_folder = './samples'\n",
        "img_size = 64  # Redimensionar imagens para 64x64 pixels\n",
        "\n",
        "# Carregar imagens de treino\n",
        "X_train, y_train = load_images_from_folder(train_folder, img_size)\n",
        "\n",
        "# Para o conjunto de teste, podemos simplesmente carregar as imagens sem etiquetas\n",
        "# ou usar um conjunto de validação a partir dos dados de treinamento\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
        "\n",
        "X_submission, _ = load_images_from_folder(submission_folder, img_size, sort=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-07-19T21:09:02.771592Z",
          "iopub.status.busy": "2024-07-19T21:09:02.770393Z",
          "iopub.status.idle": "2024-07-19T21:09:03.379545Z",
          "shell.execute_reply": "2024-07-19T21:09:03.377878Z",
          "shell.execute_reply.started": "2024-07-19T21:09:02.771524Z"
        },
        "id": "Y3m-cVRfoD-5",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Normalizar os dados\n",
        "X_train = X_train.astype('float32') / 255.0\n",
        "X_test = X_test.astype('float32') / 255.0\n",
        "X_submission = X_submission.astype('float32') / 255.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-07-19T21:09:03.406877Z",
          "iopub.status.busy": "2024-07-19T21:09:03.406353Z",
          "iopub.status.idle": "2024-07-19T21:09:03.414786Z",
          "shell.execute_reply": "2024-07-19T21:09:03.413427Z",
          "shell.execute_reply.started": "2024-07-19T21:09:03.406840Z"
        },
        "id": "gt3uv7B5oD-5",
        "outputId": "500097a7-d9d8-427f-be77-b05a07b69bae",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(5000, 12288)\n",
            "(1250, 12288)\n",
            "(100, 12288)\n"
          ]
        }
      ],
      "source": [
        "X_train_flat = X_train.reshape((X_train.shape[0], -1))\n",
        "X_test_flat = X_test.reshape((X_test.shape[0], -1))\n",
        "X_submission_flat = X_submission.reshape((X_submission.shape[0], -1))\n",
        "\n",
        "print(X_train_flat.shape)\n",
        "print(X_test_flat.shape)\n",
        "print(X_submission_flat.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-07-19T21:09:03.421516Z",
          "iopub.status.busy": "2024-07-19T21:09:03.421093Z",
          "iopub.status.idle": "2024-07-19T21:09:45.867844Z",
          "shell.execute_reply": "2024-07-19T21:09:45.866188Z",
          "shell.execute_reply.started": "2024-07-19T21:09:03.421482Z"
        },
        "id": "r4KXZLcOoD-5",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "from sklearn.decomposition import PCA\n",
        "\n",
        "n_components = 500\n",
        "pca = PCA(n_components=n_components)\n",
        "X_train_pca = pca.fit_transform(X_train_flat)\n",
        "X_test_pca = pca.transform(X_test_flat)\n",
        "X_submission_pca = pca.transform(X_submission_flat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-07-19T21:09:46.288254Z",
          "iopub.status.busy": "2024-07-19T21:09:46.287811Z",
          "iopub.status.idle": "2024-07-19T21:09:47.966624Z",
          "shell.execute_reply": "2024-07-19T21:09:47.965006Z",
          "shell.execute_reply.started": "2024-07-19T21:09:46.288211Z"
        },
        "id": "dALXEGG4oD-6",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "# Treinamento de um modelo Regressão Logistica\n",
        "def train(X_train, y_train):\n",
        "  model = LogisticRegression(max_iter=10000)\n",
        "  model.fit(X_train, y_train)\n",
        "  return model\n",
        "\n",
        "model = train(X_train_pca, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-07-19T21:09:47.985187Z",
          "iopub.status.busy": "2024-07-19T21:09:47.983952Z",
          "iopub.status.idle": "2024-07-19T21:09:49.648188Z",
          "shell.execute_reply": "2024-07-19T21:09:49.646842Z",
          "shell.execute_reply.started": "2024-07-19T21:09:47.985123Z"
        },
        "id": "Zdaci2nJoD-6",
        "outputId": "d351bd5f-491c-42e6-de18-643990f93ada",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Resultados de Treino\n",
            "Acurácia: 0.6858\n",
            "F1 score: 0.685790762357048\n",
            "Resultados de Teste\n",
            "Acurácia: 0.6024\n",
            "F1 score: 0.6023172661064425\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score, cohen_kappa_score, f1_score, confusion_matrix\n",
        "import seaborn as sns\n",
        "\n",
        "# Inferência e avaliação\n",
        "def predict_and_evaluate(model, X_test, y_test):\n",
        "\n",
        "    # Inferência\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    # Métricas\n",
        "    print('Acurácia:', accuracy_score(y_test, y_pred))\n",
        "    print('F1 score:', f1_score(y_test, y_pred, average='weighted'))\n",
        "\n",
        "    # Matriz de confusão\n",
        "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "    # sns.heatmap(conf_matrix, annot=True, fmt='d', cmap=\"Blues\", xticklabels=np.unique(y_test), yticklabels=np.unique(y_test))\n",
        "    # plt.title('Matriz de Confusão')\n",
        "    # plt.xlabel('Predito')\n",
        "    # plt.ylabel('Verdadeiro')\n",
        "    # plt.show()\n",
        "\n",
        "print('Resultados de Treino')\n",
        "predict_and_evaluate(model, X_train_pca, y_train)\n",
        "print('Resultados de Teste')\n",
        "predict_and_evaluate(model, X_test_pca, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-07-19T21:09:49.650698Z",
          "iopub.status.busy": "2024-07-19T21:09:49.650145Z",
          "iopub.status.idle": "2024-07-19T21:21:46.283956Z",
          "shell.execute_reply": "2024-07-19T21:21:46.282857Z",
          "shell.execute_reply.started": "2024-07-19T21:09:49.650653Z"
        },
        "id": "U9KBn3jMoD-6",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "from skimage.feature import hog\n",
        "# Extração de características utilizando HOG\n",
        "def extract_hog_features(images):\n",
        "    hog_features = []\n",
        "    hog_images = []\n",
        "    for image in images:\n",
        "        features, img = hog(image, orientations=9,      # o número de direções angulares distintas para as quais os gradientes são calculados\n",
        "                              pixels_per_cell=(8, 8),   # tamanho (em pixels) de cada célula na qual a imagem é dividida para calcular o histograma de gradientes orientados\n",
        "                              cells_per_block=(2, 2),   # número de células em cada bloco. Os blocos são usados para normalizar os histogramas de gradientes dentro de células, melhorando a robustez a variações de iluminação e contraste.\n",
        "                              visualize=True,           # se a imagem HOG (uma representação visual das características HOG) deve ser retornada junto com o vetor de características.\n",
        "                              channel_axis=-1)          # índice do eixo do canal na imagem de entrada.\n",
        "        hog_features.append(features)\n",
        "        hog_images.append(img)\n",
        "    return np.array(hog_features), hog_images\n",
        "\n",
        "# Extraindo características HOG dos dados de treinamento e teste\n",
        "X_train_hog, train_hog_images = extract_hog_features(X_train)\n",
        "X_test_hog, _ = extract_hog_features(X_test)\n",
        "X_submission_hog, _ = extract_hog_features(X_submission)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-07-19T21:21:47.111386Z",
          "iopub.status.busy": "2024-07-19T21:21:47.110991Z",
          "iopub.status.idle": "2024-07-19T21:21:58.799900Z",
          "shell.execute_reply": "2024-07-19T21:21:58.798638Z",
          "shell.execute_reply.started": "2024-07-19T21:21:47.111354Z"
        },
        "id": "gPxiz1U-oD-6",
        "outputId": "fce2e4c2-f1a0-43f4-bfb8-cf56da11f74b",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Resultados de Treino\n",
            "Acurácia: 0.8116\n",
            "F1 score: 0.811580765539811\n",
            "Resultados de Teste\n",
            "Acurácia: 0.6728\n",
            "F1 score: 0.6727319151660663\n"
          ]
        }
      ],
      "source": [
        "model = train(X_train_hog, y_train)\n",
        "\n",
        "print('Resultados de Treino')\n",
        "predict_and_evaluate(model, X_train_hog, y_train)\n",
        "print('Resultados de Teste')\n",
        "predict_and_evaluate(model, X_test_hog, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OZYAaMhZoJso"
      },
      "source": [
        "# Exercício: Concatene os componentes principais e as features extraídas com HOG e treine novamente o modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-07-19T21:21:58.801956Z",
          "iopub.status.busy": "2024-07-19T21:21:58.801474Z",
          "iopub.status.idle": "2024-07-19T21:21:58.807849Z",
          "shell.execute_reply": "2024-07-19T21:21:58.806639Z",
          "shell.execute_reply.started": "2024-07-19T21:21:58.801918Z"
        },
        "id": "YfjIvaGyoD-7",
        "outputId": "b3ed5523-3f62-48f5-c741-4e82e5b52da4",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(5000, 1764)\n",
            "(5000, 500)\n"
          ]
        }
      ],
      "source": [
        "print(X_train_hog.shape)\n",
        "print(X_train_pca.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "KkvPI0NLoknN"
      },
      "outputs": [],
      "source": [
        "# Concatenar as características HOG e PCA\n",
        "X_train_concat = np.hstack((X_train_hog, X_train_pca))\n",
        "X_test_concat = np.hstack((X_test_hog, X_test_pca))\n",
        "X_submission_concat = np.hstack((X_submission_hog, X_submission_pca))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "5dRZKbH0okrE"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(5000, 2264)\n"
          ]
        }
      ],
      "source": [
        "print(X_train_concat.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "2L7L3wYkoku0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Resultados de Treino\n",
            "Acurácia: 0.8598\n",
            "F1 score: 0.8598000729044929\n",
            "Resultados de Teste\n",
            "Acurácia: 0.684\n",
            "F1 score: 0.6838127639512636\n"
          ]
        }
      ],
      "source": [
        "model = train(X_train_concat, y_train)\n",
        "\n",
        "print('Resultados de Treino')\n",
        "predict_and_evaluate(model, X_train_concat, y_train)\n",
        "print('Resultados de Teste')\n",
        "predict_and_evaluate(model, X_test_concat, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8-t3tth6oD-7"
      },
      "source": [
        "# Exercício: Inferir imagens para submissão no kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "qz1aTlZGorMJ"
      },
      "outputs": [],
      "source": [
        "y_pred = model.predict(X_submission_concat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "NHqo8BsForOR"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>cat</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>dog</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>dog</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>dog</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>cat</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id label\n",
              "0   1   cat\n",
              "1   2   dog\n",
              "2   3   dog\n",
              "3   4   dog\n",
              "4   5   cat"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "results = pd.DataFrame()\n",
        "results['id'] = list(range(1, y_pred.shape[0] + 1))\n",
        "results['label'] = y_pred\n",
        "results.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "ename": "SyntaxError",
          "evalue": "invalid syntax (3471390363.py, line 1)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;36m  Cell \u001b[0;32mIn[21], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    y_pred = model.predict(X_submission_concat)import pandas as pd\u001b[0m\n\u001b[0m                                               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ],
      "source": [
        "y_pred = model.predict(X_submission_concat)\n",
        "\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "\n",
        "results = pd.DataFrame()\n",
        "results['id'] = list(range(1, y_pred.shape[0] + 1))\n",
        "results['label'] = y_pred\n",
        "results.head()\n",
        "\n",
        "# Generate the current timestamp\n",
        "timestamp = datetime.now().strftime('%Y-%m-%d_%H-%M')\n",
        "\n",
        "# Generate the file name with the timestamp\n",
        "file_name = f'results_{timestamp}.csv'\n",
        "\n",
        "# Save the DataFrame to a CSV file\n",
        "results.to_csv(file_name, index=False)\n",
        "\n",
        "# Display the first few rows of the DataFrame\n",
        "results.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Tuning de parâmetros"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/teixeira/code/computer-vision-master/Técnicas Tradicionais de Classificação de Imagens/dogs-vs-cats/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import optuna\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Variáveis para armazenar o melhor modelo e a melhor métrica\n",
        "best_model = None\n",
        "best_accuracy = 0.0\n",
        "\n",
        "def objective(trial):\n",
        "\n",
        "    # Definir o espaço de busca para os hiperparâmetros\n",
        "    n_estimators = trial.suggest_int('n_estimators', 10, 200)\n",
        "    max_depth = trial.suggest_int('max_depth', 5, 40)\n",
        "    min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 30)\n",
        "\n",
        "    # Cria modelo\n",
        "    model = RandomForestClassifier(n_estimators=n_estimators,\n",
        "                                   max_depth=max_depth,\n",
        "                                   min_samples_leaf=min_samples_leaf,\n",
        "                                   random_state=42)\n",
        "\n",
        "    model.fit(X_train_concat, y_train)  # Treina\n",
        "    y_pred = model.predict(X_test_concat)  # Infere\n",
        "    accuracy = accuracy_score(y_test, y_pred)  # Calcula métrica\n",
        "\n",
        "    # Atualize o melhor modelo se necessário\n",
        "    global best_model, best_accuracy\n",
        "    if accuracy > best_accuracy:\n",
        "        best_model = model\n",
        "        best_accuracy = accuracy\n",
        "\n",
        "    return accuracy\n",
        "\n",
        "# Cria estudo a ser otimizado\n",
        "# study = optuna.create_study(direction='maximize')\n",
        "# study.optimize(objective, n_trials=100, n_jobs=-1)\n",
        "\n",
        "# # Imprime a evolução dos modelos ao final da otimização\n",
        "# print(f'Melhor solução:')\n",
        "# trial = study.best_trial\n",
        "\n",
        "# print(f'Valor: {trial.value}')\n",
        "# print(f'Parâmetros: ')\n",
        "# for key, value in trial.params.items():\n",
        "#     print(f'    {key}: {value}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-08-07 01:49:00,077] A new study created in memory with name: no-name-2bcd1853-3b89-4ca5-8751-4d5ebd947add\n",
            "[I 2024-08-07 01:51:08,334] Trial 0 finished with value: 0.7056 and parameters: {'n_estimators': 126, 'max_depth': 29, 'learning_rate': 0.013428133496533382}. Best is trial 0 with value: 0.7056.\n",
            "[I 2024-08-07 01:52:50,648] Trial 1 finished with value: 0.7096 and parameters: {'n_estimators': 114, 'max_depth': 23, 'learning_rate': 0.02757334649604389}. Best is trial 1 with value: 0.7096.\n",
            "[I 2024-08-07 01:53:58,948] Trial 2 finished with value: 0.7336 and parameters: {'n_estimators': 160, 'max_depth': 12, 'learning_rate': 0.08510748626525892}. Best is trial 2 with value: 0.7336.\n",
            "[I 2024-08-07 01:54:07,616] Trial 3 finished with value: 0.7064 and parameters: {'n_estimators': 73, 'max_depth': 5, 'learning_rate': 0.1049343633470188}. Best is trial 2 with value: 0.7336.\n",
            "[I 2024-08-07 01:54:32,766] Trial 4 finished with value: 0.7184 and parameters: {'n_estimators': 90, 'max_depth': 7, 'learning_rate': 0.026958027118305784}. Best is trial 2 with value: 0.7336.\n",
            "[I 2024-08-07 01:54:48,842] Trial 5 finished with value: 0.6952 and parameters: {'n_estimators': 20, 'max_depth': 23, 'learning_rate': 0.24031089643629347}. Best is trial 2 with value: 0.7336.\n",
            "[I 2024-08-07 01:55:17,348] Trial 6 finished with value: 0.704 and parameters: {'n_estimators': 32, 'max_depth': 36, 'learning_rate': 0.11038934582454757}. Best is trial 2 with value: 0.7336.\n",
            "[I 2024-08-07 01:55:48,006] Trial 7 finished with value: 0.7232 and parameters: {'n_estimators': 127, 'max_depth': 7, 'learning_rate': 0.08111802310698579}. Best is trial 2 with value: 0.7336.\n",
            "[I 2024-08-07 01:56:08,168] Trial 8 finished with value: 0.7344 and parameters: {'n_estimators': 119, 'max_depth': 6, 'learning_rate': 0.09451856921495988}. Best is trial 8 with value: 0.7344.\n",
            "[I 2024-08-07 01:56:46,529] Trial 9 finished with value: 0.712 and parameters: {'n_estimators': 85, 'max_depth': 12, 'learning_rate': 0.1458190255173893}. Best is trial 8 with value: 0.7344.\n",
            "[I 2024-08-07 01:58:43,108] Trial 10 finished with value: 0.7288 and parameters: {'n_estimators': 193, 'max_depth': 16, 'learning_rate': 0.0409189578015251}. Best is trial 8 with value: 0.7344.\n",
            "[I 2024-08-07 02:00:08,965] Trial 11 finished with value: 0.724 and parameters: {'n_estimators': 164, 'max_depth': 15, 'learning_rate': 0.05805648527329284}. Best is trial 8 with value: 0.7344.\n",
            "[I 2024-08-07 02:00:43,043] Trial 12 finished with value: 0.732 and parameters: {'n_estimators': 148, 'max_depth': 12, 'learning_rate': 0.24195446470583437}. Best is trial 8 with value: 0.7344.\n",
            "[I 2024-08-07 02:02:14,767] Trial 13 finished with value: 0.7336 and parameters: {'n_estimators': 199, 'max_depth': 19, 'learning_rate': 0.0598252042610312}. Best is trial 8 with value: 0.7344.\n",
            "[I 2024-08-07 02:02:56,052] Trial 14 finished with value: 0.728 and parameters: {'n_estimators': 159, 'max_depth': 10, 'learning_rate': 0.15743774491404228}. Best is trial 8 with value: 0.7344.\n",
            "[I 2024-08-07 02:03:44,405] Trial 15 finished with value: 0.7024 and parameters: {'n_estimators': 52, 'max_depth': 18, 'learning_rate': 0.03894457221031271}. Best is trial 8 with value: 0.7344.\n",
            "[I 2024-08-07 02:04:56,239] Trial 16 finished with value: 0.7288 and parameters: {'n_estimators': 175, 'max_depth': 39, 'learning_rate': 0.08422569664610356}. Best is trial 8 with value: 0.7344.\n",
            "[I 2024-08-07 02:05:40,046] Trial 17 finished with value: 0.7272 and parameters: {'n_estimators': 139, 'max_depth': 30, 'learning_rate': 0.1657399609586725}. Best is trial 8 with value: 0.7344.\n",
            "[I 2024-08-07 02:06:52,969] Trial 18 finished with value: 0.7024 and parameters: {'n_estimators': 108, 'max_depth': 10, 'learning_rate': 0.01281929832014548}. Best is trial 8 with value: 0.7344.\n",
            "[I 2024-08-07 02:07:11,425] Trial 19 finished with value: 0.7352 and parameters: {'n_estimators': 178, 'max_depth': 5, 'learning_rate': 0.0756293374167248}. Best is trial 19 with value: 0.7352.\n",
            "[I 2024-08-07 02:07:56,989] Trial 20 finished with value: 0.724 and parameters: {'n_estimators': 182, 'max_depth': 7, 'learning_rate': 0.02022574510330524}. Best is trial 19 with value: 0.7352.\n",
            "[I 2024-08-07 02:08:12,228] Trial 21 finished with value: 0.7296 and parameters: {'n_estimators': 146, 'max_depth': 5, 'learning_rate': 0.07081592807704178}. Best is trial 19 with value: 0.7352.\n",
            "[I 2024-08-07 02:09:03,269] Trial 22 finished with value: 0.7384 and parameters: {'n_estimators': 168, 'max_depth': 10, 'learning_rate': 0.11175088098005516}. Best is trial 22 with value: 0.7384.\n",
            "[I 2024-08-07 02:09:48,156] Trial 23 finished with value: 0.7272 and parameters: {'n_estimators': 177, 'max_depth': 9, 'learning_rate': 0.12976934934414433}. Best is trial 22 with value: 0.7384.\n",
            "[I 2024-08-07 02:11:14,235] Trial 24 finished with value: 0.7128 and parameters: {'n_estimators': 129, 'max_depth': 14, 'learning_rate': 0.04781150095957864}. Best is trial 22 with value: 0.7384.\n",
            "[I 2024-08-07 02:11:34,653] Trial 25 finished with value: 0.7312 and parameters: {'n_estimators': 186, 'max_depth': 5, 'learning_rate': 0.18690268897194276}. Best is trial 22 with value: 0.7384.\n",
            "[I 2024-08-07 02:12:38,723] Trial 26 finished with value: 0.7392 and parameters: {'n_estimators': 167, 'max_depth': 19, 'learning_rate': 0.10764083647782625}. Best is trial 26 with value: 0.7392.\n",
            "[I 2024-08-07 02:13:14,346] Trial 27 finished with value: 0.716 and parameters: {'n_estimators': 168, 'max_depth': 26, 'learning_rate': 0.2974913531347013}. Best is trial 26 with value: 0.7392.\n",
            "[I 2024-08-07 02:14:12,262] Trial 28 finished with value: 0.7288 and parameters: {'n_estimators': 152, 'max_depth': 19, 'learning_rate': 0.12142724202190432}. Best is trial 26 with value: 0.7392.\n",
            "[I 2024-08-07 02:15:29,423] Trial 29 finished with value: 0.7256 and parameters: {'n_estimators': 136, 'max_depth': 30, 'learning_rate': 0.06869873310088266}. Best is trial 26 with value: 0.7392.\n",
            "[I 2024-08-07 02:16:17,424] Trial 30 finished with value: 0.7304 and parameters: {'n_estimators': 199, 'max_depth': 21, 'learning_rate': 0.19872170551686277}. Best is trial 26 with value: 0.7392.\n",
            "[I 2024-08-07 02:17:08,957] Trial 31 finished with value: 0.7344 and parameters: {'n_estimators': 173, 'max_depth': 9, 'learning_rate': 0.10680401167720022}. Best is trial 26 with value: 0.7392.\n",
            "[I 2024-08-07 02:18:06,292] Trial 32 finished with value: 0.7176 and parameters: {'n_estimators': 103, 'max_depth': 26, 'learning_rate': 0.09504082819987994}. Best is trial 26 with value: 0.7392.\n",
            "[I 2024-08-07 02:19:55,947] Trial 33 finished with value: 0.708 and parameters: {'n_estimators': 117, 'max_depth': 13, 'learning_rate': 0.010437388383178413}. Best is trial 26 with value: 0.7392.\n",
            "[I 2024-08-07 02:20:44,797] Trial 34 finished with value: 0.7192 and parameters: {'n_estimators': 159, 'max_depth': 8, 'learning_rate': 0.07094674434284697}. Best is trial 26 with value: 0.7392.\n",
            "[I 2024-08-07 02:21:37,147] Trial 35 finished with value: 0.7328 and parameters: {'n_estimators': 188, 'max_depth': 11, 'learning_rate': 0.13007248195176518}. Best is trial 26 with value: 0.7392.\n",
            "[I 2024-08-07 02:21:44,766] Trial 36 finished with value: 0.712 and parameters: {'n_estimators': 66, 'max_depth': 5, 'learning_rate': 0.04784557892139139}. Best is trial 26 with value: 0.7392.\n",
            "[I 2024-08-07 02:22:42,821] Trial 37 finished with value: 0.7144 and parameters: {'n_estimators': 118, 'max_depth': 16, 'learning_rate': 0.08790908801134098}. Best is trial 26 with value: 0.7392.\n",
            "[I 2024-08-07 02:23:07,997] Trial 38 finished with value: 0.7216 and parameters: {'n_estimators': 97, 'max_depth': 7, 'learning_rate': 0.02982899037801643}. Best is trial 26 with value: 0.7392.\n",
            "[I 2024-08-07 02:24:07,179] Trial 39 finished with value: 0.7248 and parameters: {'n_estimators': 136, 'max_depth': 33, 'learning_rate': 0.09958203624823478}. Best is trial 26 with value: 0.7392.\n",
            "[I 2024-08-07 02:25:20,077] Trial 40 finished with value: 0.7336 and parameters: {'n_estimators': 148, 'max_depth': 21, 'learning_rate': 0.0721916528591799}. Best is trial 26 with value: 0.7392.\n",
            "[I 2024-08-07 02:26:07,612] Trial 41 finished with value: 0.7384 and parameters: {'n_estimators': 172, 'max_depth': 9, 'learning_rate': 0.10947039586727113}. Best is trial 26 with value: 0.7392.\n",
            "[I 2024-08-07 02:26:40,696] Trial 42 finished with value: 0.728 and parameters: {'n_estimators': 171, 'max_depth': 7, 'learning_rate': 0.12442342203286455}. Best is trial 26 with value: 0.7392.\n",
            "[I 2024-08-07 02:27:33,909] Trial 43 finished with value: 0.7288 and parameters: {'n_estimators': 159, 'max_depth': 11, 'learning_rate': 0.11008095876336423}. Best is trial 26 with value: 0.7392.\n",
            "[I 2024-08-07 02:28:16,058] Trial 44 finished with value: 0.7416 and parameters: {'n_estimators': 182, 'max_depth': 9, 'learning_rate': 0.15045363367488304}. Best is trial 44 with value: 0.7416.\n",
            "[I 2024-08-07 02:28:58,755] Trial 45 finished with value: 0.728 and parameters: {'n_estimators': 180, 'max_depth': 14, 'learning_rate': 0.19654408250335165}. Best is trial 44 with value: 0.7416.\n",
            "[I 2024-08-07 02:29:39,679] Trial 46 finished with value: 0.7248 and parameters: {'n_estimators': 193, 'max_depth': 9, 'learning_rate': 0.16804048453927298}. Best is trial 44 with value: 0.7416.\n",
            "[I 2024-08-07 02:30:30,284] Trial 47 finished with value: 0.736 and parameters: {'n_estimators': 165, 'max_depth': 17, 'learning_rate': 0.14311059178672014}. Best is trial 44 with value: 0.7416.\n",
            "[I 2024-08-07 02:31:08,441] Trial 48 finished with value: 0.7192 and parameters: {'n_estimators': 166, 'max_depth': 17, 'learning_rate': 0.2381435882081208}. Best is trial 44 with value: 0.7416.\n",
            "[I 2024-08-07 02:31:57,731] Trial 49 finished with value: 0.7272 and parameters: {'n_estimators': 156, 'max_depth': 25, 'learning_rate': 0.14683007551712016}. Best is trial 44 with value: 0.7416.\n",
            "[I 2024-08-07 02:32:52,060] Trial 50 finished with value: 0.7296 and parameters: {'n_estimators': 188, 'max_depth': 20, 'learning_rate': 0.13966798750309914}. Best is trial 44 with value: 0.7416.\n",
            "[I 2024-08-07 02:34:00,179] Trial 51 finished with value: 0.7264 and parameters: {'n_estimators': 164, 'max_depth': 13, 'learning_rate': 0.08086432401267608}. Best is trial 44 with value: 0.7416.\n",
            "[I 2024-08-07 02:35:01,028] Trial 52 finished with value: 0.7328 and parameters: {'n_estimators': 180, 'max_depth': 23, 'learning_rate': 0.11422541366910291}. Best is trial 44 with value: 0.7416.\n",
            "[I 2024-08-07 02:35:09,166] Trial 53 finished with value: 0.6856 and parameters: {'n_estimators': 10, 'max_depth': 11, 'learning_rate': 0.17554326246109134}. Best is trial 44 with value: 0.7416.\n",
            "[I 2024-08-07 02:35:51,172] Trial 54 finished with value: 0.7304 and parameters: {'n_estimators': 194, 'max_depth': 16, 'learning_rate': 0.21710280082211264}. Best is trial 44 with value: 0.7416.\n",
            "[I 2024-08-07 02:36:27,377] Trial 55 finished with value: 0.7312 and parameters: {'n_estimators': 172, 'max_depth': 8, 'learning_rate': 0.15118527338195104}. Best is trial 44 with value: 0.7416.\n",
            "[I 2024-08-07 02:36:49,885] Trial 56 finished with value: 0.7304 and parameters: {'n_estimators': 143, 'max_depth': 6, 'learning_rate': 0.06120270436902825}. Best is trial 44 with value: 0.7416.\n",
            "[I 2024-08-07 02:37:55,943] Trial 57 finished with value: 0.7288 and parameters: {'n_estimators': 153, 'max_depth': 14, 'learning_rate': 0.08362560521779229}. Best is trial 44 with value: 0.7416.\n",
            "[I 2024-08-07 02:39:04,524] Trial 58 finished with value: 0.732 and parameters: {'n_estimators': 184, 'max_depth': 18, 'learning_rate': 0.0931605587394925}. Best is trial 44 with value: 0.7416.\n",
            "[I 2024-08-07 02:39:34,887] Trial 59 finished with value: 0.7464 and parameters: {'n_estimators': 165, 'max_depth': 10, 'learning_rate': 0.2945778296962904}. Best is trial 59 with value: 0.7464.\n",
            "[I 2024-08-07 02:40:05,649] Trial 60 finished with value: 0.7248 and parameters: {'n_estimators': 127, 'max_depth': 12, 'learning_rate': 0.2613613575414855}. Best is trial 59 with value: 0.7464.\n",
            "[I 2024-08-07 02:40:50,941] Trial 61 finished with value: 0.744 and parameters: {'n_estimators': 165, 'max_depth': 10, 'learning_rate': 0.13718310631179623}. Best is trial 59 with value: 0.7464.\n",
            "[I 2024-08-07 02:41:20,877] Trial 62 finished with value: 0.7328 and parameters: {'n_estimators': 165, 'max_depth': 10, 'learning_rate': 0.2981881825107979}. Best is trial 59 with value: 0.7464.\n",
            "[I 2024-08-07 02:42:11,252] Trial 63 finished with value: 0.7328 and parameters: {'n_estimators': 151, 'max_depth': 15, 'learning_rate': 0.1347362807065766}. Best is trial 59 with value: 0.7464.\n",
            "[I 2024-08-07 02:42:53,916] Trial 64 finished with value: 0.7312 and parameters: {'n_estimators': 174, 'max_depth': 10, 'learning_rate': 0.16049287280327718}. Best is trial 59 with value: 0.7464.\n",
            "[I 2024-08-07 02:43:33,587] Trial 65 finished with value: 0.728 and parameters: {'n_estimators': 162, 'max_depth': 13, 'learning_rate': 0.20836563319578633}. Best is trial 59 with value: 0.7464.\n",
            "[I 2024-08-07 02:44:29,089] Trial 66 finished with value: 0.7296 and parameters: {'n_estimators': 168, 'max_depth': 12, 'learning_rate': 0.11436156759950243}. Best is trial 59 with value: 0.7464.\n",
            "[I 2024-08-07 02:44:59,428] Trial 67 finished with value: 0.7304 and parameters: {'n_estimators': 140, 'max_depth': 8, 'learning_rate': 0.18293509810619285}. Best is trial 59 with value: 0.7464.\n",
            "[I 2024-08-07 02:45:34,853] Trial 68 finished with value: 0.7312 and parameters: {'n_estimators': 193, 'max_depth': 9, 'learning_rate': 0.22764334450173093}. Best is trial 59 with value: 0.7464.\n",
            "[I 2024-08-07 02:46:32,587] Trial 69 finished with value: 0.7376 and parameters: {'n_estimators': 133, 'max_depth': 23, 'learning_rate': 0.10056809842562096}. Best is trial 59 with value: 0.7464.\n",
            "[I 2024-08-07 02:47:35,304] Trial 70 finished with value: 0.7328 and parameters: {'n_estimators': 157, 'max_depth': 24, 'learning_rate': 0.09819998548866733}. Best is trial 59 with value: 0.7464.\n",
            "[I 2024-08-07 02:48:35,012] Trial 71 finished with value: 0.74 and parameters: {'n_estimators': 179, 'max_depth': 22, 'learning_rate': 0.1170686038045537}. Best is trial 59 with value: 0.7464.\n",
            "[I 2024-08-07 02:49:32,990] Trial 72 finished with value: 0.7248 and parameters: {'n_estimators': 175, 'max_depth': 28, 'learning_rate': 0.12154976003379125}. Best is trial 59 with value: 0.7464.\n",
            "[I 2024-08-07 02:50:27,229] Trial 73 finished with value: 0.732 and parameters: {'n_estimators': 132, 'max_depth': 23, 'learning_rate': 0.1115659293943137}. Best is trial 59 with value: 0.7464.\n",
            "[I 2024-08-07 02:51:34,197] Trial 74 finished with value: 0.72 and parameters: {'n_estimators': 185, 'max_depth': 21, 'learning_rate': 0.09961493179670639}. Best is trial 59 with value: 0.7464.\n",
            "[I 2024-08-07 02:52:15,827] Trial 75 finished with value: 0.7112 and parameters: {'n_estimators': 85, 'max_depth': 22, 'learning_rate': 0.1290094621878841}. Best is trial 59 with value: 0.7464.\n",
            "[I 2024-08-07 02:52:45,944] Trial 76 finished with value: 0.7336 and parameters: {'n_estimators': 199, 'max_depth': 6, 'learning_rate': 0.09031053243862912}. Best is trial 59 with value: 0.7464.\n",
            "[I 2024-08-07 02:53:22,255] Trial 77 finished with value: 0.7248 and parameters: {'n_estimators': 179, 'max_depth': 19, 'learning_rate': 0.2704438159820253}. Best is trial 59 with value: 0.7464.\n",
            "[I 2024-08-07 02:54:46,939] Trial 78 finished with value: 0.7128 and parameters: {'n_estimators': 144, 'max_depth': 26, 'learning_rate': 0.05365305471512566}. Best is trial 59 with value: 0.7464.\n",
            "[I 2024-08-07 02:55:47,790] Trial 79 finished with value: 0.7408 and parameters: {'n_estimators': 111, 'max_depth': 28, 'learning_rate': 0.08038599440202981}. Best is trial 59 with value: 0.7464.\n",
            "[I 2024-08-07 02:56:18,269] Trial 80 finished with value: 0.6984 and parameters: {'n_estimators': 32, 'max_depth': 36, 'learning_rate': 0.06455858202951124}. Best is trial 59 with value: 0.7464.\n",
            "[I 2024-08-07 02:57:20,260] Trial 81 finished with value: 0.7176 and parameters: {'n_estimators': 112, 'max_depth': 29, 'learning_rate': 0.07806880222677581}. Best is trial 59 with value: 0.7464.\n",
            "[I 2024-08-07 02:58:15,409] Trial 82 finished with value: 0.728 and parameters: {'n_estimators': 121, 'max_depth': 28, 'learning_rate': 0.10251363689634405}. Best is trial 59 with value: 0.7464.\n",
            "[I 2024-08-07 02:59:04,103] Trial 83 finished with value: 0.7328 and parameters: {'n_estimators': 95, 'max_depth': 34, 'learning_rate': 0.10711658833625368}. Best is trial 59 with value: 0.7464.\n",
            "[I 2024-08-07 02:59:45,732] Trial 84 finished with value: 0.7248 and parameters: {'n_estimators': 76, 'max_depth': 32, 'learning_rate': 0.1193355107995449}. Best is trial 59 with value: 0.7464.\n",
            "[I 2024-08-07 03:00:41,218] Trial 85 finished with value: 0.732 and parameters: {'n_estimators': 103, 'max_depth': 24, 'learning_rate': 0.08944274975362125}. Best is trial 59 with value: 0.7464.\n",
            "[I 2024-08-07 03:01:32,712] Trial 86 finished with value: 0.7216 and parameters: {'n_estimators': 190, 'max_depth': 27, 'learning_rate': 0.15462388769766316}. Best is trial 59 with value: 0.7464.\n",
            "[I 2024-08-07 03:02:25,451] Trial 87 finished with value: 0.732 and parameters: {'n_estimators': 170, 'max_depth': 22, 'learning_rate': 0.1368089569180615}. Best is trial 59 with value: 0.7464.\n",
            "[I 2024-08-07 03:03:08,055] Trial 88 finished with value: 0.7296 and parameters: {'n_estimators': 152, 'max_depth': 8, 'learning_rate': 0.08479032060803797}. Best is trial 59 with value: 0.7464.\n",
            "[I 2024-08-07 03:04:18,347] Trial 89 finished with value: 0.7304 and parameters: {'n_estimators': 182, 'max_depth': 11, 'learning_rate': 0.07550177272932274}. Best is trial 59 with value: 0.7464.\n",
            "[I 2024-08-07 03:04:59,682] Trial 90 finished with value: 0.7168 and parameters: {'n_estimators': 122, 'max_depth': 31, 'learning_rate': 0.1675847360098275}. Best is trial 59 with value: 0.7464.\n",
            "[I 2024-08-07 03:05:50,016] Trial 91 finished with value: 0.7296 and parameters: {'n_estimators': 162, 'max_depth': 17, 'learning_rate': 0.14229789604858026}. Best is trial 59 with value: 0.7464.\n",
            "[I 2024-08-07 03:06:45,637] Trial 92 finished with value: 0.736 and parameters: {'n_estimators': 176, 'max_depth': 20, 'learning_rate': 0.12670790055640538}. Best is trial 59 with value: 0.7464.\n",
            "[I 2024-08-07 03:07:47,361] Trial 93 finished with value: 0.724 and parameters: {'n_estimators': 168, 'max_depth': 24, 'learning_rate': 0.10533986980323364}. Best is trial 59 with value: 0.7464.\n",
            "[I 2024-08-07 03:08:35,893] Trial 94 finished with value: 0.732 and parameters: {'n_estimators': 158, 'max_depth': 20, 'learning_rate': 0.15013039833355876}. Best is trial 59 with value: 0.7464.\n",
            "[I 2024-08-07 03:10:51,603] Trial 95 finished with value: 0.7144 and parameters: {'n_estimators': 171, 'max_depth': 18, 'learning_rate': 0.02200489871745702}. Best is trial 59 with value: 0.7464.\n",
            "[I 2024-08-07 03:11:36,771] Trial 96 finished with value: 0.72 and parameters: {'n_estimators': 164, 'max_depth': 9, 'learning_rate': 0.11558710791029578}. Best is trial 59 with value: 0.7464.\n",
            "[I 2024-08-07 03:12:15,120] Trial 97 finished with value: 0.7312 and parameters: {'n_estimators': 155, 'max_depth': 11, 'learning_rate': 0.1915670232169958}. Best is trial 59 with value: 0.7464.\n",
            "[I 2024-08-07 03:12:55,717] Trial 98 finished with value: 0.7336 and parameters: {'n_estimators': 177, 'max_depth': 10, 'learning_rate': 0.17694689360376792}. Best is trial 59 with value: 0.7464.\n",
            "[I 2024-08-07 03:13:54,011] Trial 99 finished with value: 0.732 and parameters: {'n_estimators': 147, 'max_depth': 12, 'learning_rate': 0.09346510804998671}. Best is trial 59 with value: 0.7464.\n",
            "[I 2024-08-07 03:14:38,488] Trial 100 finished with value: 0.7248 and parameters: {'n_estimators': 110, 'max_depth': 14, 'learning_rate': 0.1332491146468516}. Best is trial 59 with value: 0.7464.\n",
            "[I 2024-08-07 03:15:36,040] Trial 101 finished with value: 0.7312 and parameters: {'n_estimators': 175, 'max_depth': 19, 'learning_rate': 0.12110933655061133}. Best is trial 59 with value: 0.7464.\n",
            "[I 2024-08-07 03:16:32,621] Trial 102 finished with value: 0.724 and parameters: {'n_estimators': 183, 'max_depth': 21, 'learning_rate': 0.12760071573354856}. Best is trial 59 with value: 0.7464.\n",
            "[I 2024-08-07 03:17:36,870] Trial 103 finished with value: 0.732 and parameters: {'n_estimators': 188, 'max_depth': 22, 'learning_rate': 0.10602554422913155}. Best is trial 59 with value: 0.7464.\n",
            "[I 2024-08-07 03:18:29,183] Trial 104 finished with value: 0.7232 and parameters: {'n_estimators': 179, 'max_depth': 20, 'learning_rate': 0.14216462045083583}. Best is trial 59 with value: 0.7464.\n",
            "[I 2024-08-07 03:19:16,277] Trial 105 finished with value: 0.7256 and parameters: {'n_estimators': 161, 'max_depth': 17, 'learning_rate': 0.16038523954003003}. Best is trial 59 with value: 0.7464.\n",
            "[I 2024-08-07 03:20:21,974] Trial 106 finished with value: 0.7288 and parameters: {'n_estimators': 172, 'max_depth': 40, 'learning_rate': 0.0963169037957536}. Best is trial 59 with value: 0.7464.\n",
            "[I 2024-08-07 03:20:55,791] Trial 107 finished with value: 0.7424 and parameters: {'n_estimators': 167, 'max_depth': 7, 'learning_rate': 0.11230264902373008}. Best is trial 59 with value: 0.7464.\n",
            "[I 2024-08-07 03:21:18,590] Trial 108 finished with value: 0.7288 and parameters: {'n_estimators': 150, 'max_depth': 6, 'learning_rate': 0.11308372654325481}. Best is trial 59 with value: 0.7464.\n",
            "[I 2024-08-07 03:21:55,820] Trial 109 finished with value: 0.7328 and parameters: {'n_estimators': 166, 'max_depth': 7, 'learning_rate': 0.06732813564272859}. Best is trial 59 with value: 0.7464.\n",
            "[I 2024-08-07 03:22:41,559] Trial 110 finished with value: 0.728 and parameters: {'n_estimators': 168, 'max_depth': 8, 'learning_rate': 0.08224761551978811}. Best is trial 59 with value: 0.7464.\n",
            "[I 2024-08-07 03:23:36,880] Trial 111 finished with value: 0.736 and parameters: {'n_estimators': 175, 'max_depth': 18, 'learning_rate': 0.12757061956590288}. Best is trial 59 with value: 0.7464.\n",
            "[I 2024-08-07 03:24:29,553] Trial 112 finished with value: 0.7344 and parameters: {'n_estimators': 161, 'max_depth': 10, 'learning_rate': 0.10137881078003765}. Best is trial 59 with value: 0.7464.\n",
            "[I 2024-08-07 03:25:25,328] Trial 113 finished with value: 0.7456 and parameters: {'n_estimators': 155, 'max_depth': 20, 'learning_rate': 0.11808349255982195}. Best is trial 59 with value: 0.7464.\n",
            "[I 2024-08-07 03:27:00,892] Trial 114 finished with value: 0.7088 and parameters: {'n_estimators': 140, 'max_depth': 15, 'learning_rate': 0.03801151206032503}. Best is trial 59 with value: 0.7464.\n",
            "[I 2024-08-07 03:27:45,959] Trial 115 finished with value: 0.736 and parameters: {'n_estimators': 156, 'max_depth': 9, 'learning_rate': 0.11176475917241156}. Best is trial 59 with value: 0.7464.\n",
            "[I 2024-08-07 03:28:15,742] Trial 116 finished with value: 0.732 and parameters: {'n_estimators': 135, 'max_depth': 7, 'learning_rate': 0.08908626234435711}. Best is trial 59 with value: 0.7464.\n",
            "[I 2024-08-07 03:29:06,540] Trial 117 finished with value: 0.7272 and parameters: {'n_estimators': 165, 'max_depth': 25, 'learning_rate': 0.1448262839526266}. Best is trial 59 with value: 0.7464.\n",
            "[I 2024-08-07 03:29:57,751] Trial 118 finished with value: 0.7336 and parameters: {'n_estimators': 170, 'max_depth': 13, 'learning_rate': 0.1362789778017767}. Best is trial 59 with value: 0.7464.\n",
            "[I 2024-08-07 03:30:13,654] Trial 119 finished with value: 0.732 and parameters: {'n_estimators': 154, 'max_depth': 5, 'learning_rate': 0.11678960106276194}. Best is trial 59 with value: 0.7464.\n",
            "[I 2024-08-07 03:31:00,493] Trial 120 finished with value: 0.736 and parameters: {'n_estimators': 196, 'max_depth': 8, 'learning_rate': 0.10046383924927468}. Best is trial 59 with value: 0.7464.\n",
            "[I 2024-08-07 03:31:59,184] Trial 121 finished with value: 0.7368 and parameters: {'n_estimators': 181, 'max_depth': 19, 'learning_rate': 0.12032779848885305}. Best is trial 59 with value: 0.7464.\n",
            "[I 2024-08-07 03:33:02,059] Trial 122 finished with value: 0.7304 and parameters: {'n_estimators': 185, 'max_depth': 20, 'learning_rate': 0.10863099515997014}. Best is trial 59 with value: 0.7464.\n",
            "[I 2024-08-07 03:33:58,467] Trial 123 finished with value: 0.7376 and parameters: {'n_estimators': 172, 'max_depth': 23, 'learning_rate': 0.12525897805946007}. Best is trial 59 with value: 0.7464.\n",
            "[I 2024-08-07 03:35:05,550] Trial 124 finished with value: 0.7392 and parameters: {'n_estimators': 181, 'max_depth': 23, 'learning_rate': 0.09624264832158352}. Best is trial 59 with value: 0.7464.\n",
            "[I 2024-08-07 03:36:21,474] Trial 125 finished with value: 0.7272 and parameters: {'n_estimators': 172, 'max_depth': 23, 'learning_rate': 0.07565428833289832}. Best is trial 59 with value: 0.7464.\n",
            "[I 2024-08-07 03:37:28,704] Trial 126 finished with value: 0.728 and parameters: {'n_estimators': 178, 'max_depth': 24, 'learning_rate': 0.09472791492198089}. Best is trial 59 with value: 0.7464.\n",
            "[I 2024-08-07 03:38:41,377] Trial 127 finished with value: 0.732 and parameters: {'n_estimators': 188, 'max_depth': 25, 'learning_rate': 0.086520029469821}. Best is trial 59 with value: 0.7464.\n",
            "[I 2024-08-07 03:39:41,773] Trial 128 finished with value: 0.732 and parameters: {'n_estimators': 160, 'max_depth': 22, 'learning_rate': 0.10500475614624237}. Best is trial 59 with value: 0.7464.\n",
            "[I 2024-08-07 03:40:39,588] Trial 129 finished with value: 0.7352 and parameters: {'n_estimators': 168, 'max_depth': 27, 'learning_rate': 0.11817641940004772}. Best is trial 59 with value: 0.7464.\n",
            "[I 2024-08-07 03:41:35,432] Trial 130 finished with value: 0.7264 and parameters: {'n_estimators': 115, 'max_depth': 21, 'learning_rate': 0.09659613918118169}. Best is trial 59 with value: 0.7464.\n",
            "[I 2024-08-07 03:42:32,637] Trial 131 finished with value: 0.728 and parameters: {'n_estimators': 181, 'max_depth': 23, 'learning_rate': 0.12433649698592704}. Best is trial 59 with value: 0.7464.\n",
            "[I 2024-08-07 03:43:33,808] Trial 132 finished with value: 0.7264 and parameters: {'n_estimators': 181, 'max_depth': 19, 'learning_rate': 0.11257038978140678}. Best is trial 59 with value: 0.7464.\n",
            "[I 2024-08-07 03:44:30,219] Trial 133 finished with value: 0.7312 and parameters: {'n_estimators': 191, 'max_depth': 21, 'learning_rate': 0.1322690697067876}. Best is trial 59 with value: 0.7464.\n",
            "[I 2024-08-07 03:45:22,717] Trial 134 finished with value: 0.7352 and parameters: {'n_estimators': 173, 'max_depth': 11, 'learning_rate': 0.12053416055214297}. Best is trial 59 with value: 0.7464.\n",
            "[I 2024-08-07 03:46:13,526] Trial 135 finished with value: 0.7256 and parameters: {'n_estimators': 178, 'max_depth': 25, 'learning_rate': 0.15077634242229881}. Best is trial 59 with value: 0.7464.\n",
            "[I 2024-08-07 03:47:01,124] Trial 136 finished with value: 0.728 and parameters: {'n_estimators': 164, 'max_depth': 9, 'learning_rate': 0.10533493022776305}. Best is trial 59 with value: 0.7464.\n",
            "[I 2024-08-07 03:48:10,309] Trial 137 finished with value: 0.7368 and parameters: {'n_estimators': 183, 'max_depth': 22, 'learning_rate': 0.09174146270804807}. Best is trial 59 with value: 0.7464.\n",
            "[I 2024-08-07 03:48:47,777] Trial 138 finished with value: 0.7304 and parameters: {'n_estimators': 185, 'max_depth': 23, 'learning_rate': 0.2659044380285482}. Best is trial 59 with value: 0.7464.\n",
            "[I 2024-08-07 03:49:25,034] Trial 139 finished with value: 0.724 and parameters: {'n_estimators': 107, 'max_depth': 10, 'learning_rate': 0.13513604729645604}. Best is trial 59 with value: 0.7464.\n",
            "[I 2024-08-07 03:49:53,722] Trial 140 finished with value: 0.7256 and parameters: {'n_estimators': 169, 'max_depth': 6, 'learning_rate': 0.0149650087015684}. Best is trial 59 with value: 0.7464.\n",
            "[I 2024-08-07 03:51:09,092] Trial 141 finished with value: 0.7296 and parameters: {'n_estimators': 175, 'max_depth': 22, 'learning_rate': 0.0800486016073432}. Best is trial 59 with value: 0.7464.\n",
            "[I 2024-08-07 03:52:19,047] Trial 142 finished with value: 0.7352 and parameters: {'n_estimators': 183, 'max_depth': 21, 'learning_rate': 0.0902261209116186}. Best is trial 59 with value: 0.7464.\n",
            "[I 2024-08-07 03:53:15,992] Trial 143 finished with value: 0.7208 and parameters: {'n_estimators': 124, 'max_depth': 24, 'learning_rate': 0.09884839486037865}. Best is trial 59 with value: 0.7464.\n",
            "[I 2024-08-07 03:54:15,985] Trial 144 finished with value: 0.7312 and parameters: {'n_estimators': 194, 'max_depth': 22, 'learning_rate': 0.12203625618045641}. Best is trial 59 with value: 0.7464.\n",
            "[I 2024-08-07 03:55:19,317] Trial 145 finished with value: 0.7312 and parameters: {'n_estimators': 177, 'max_depth': 19, 'learning_rate': 0.10420773825544746}. Best is trial 59 with value: 0.7464.\n",
            "[I 2024-08-07 03:56:17,668] Trial 146 finished with value: 0.7272 and parameters: {'n_estimators': 159, 'max_depth': 20, 'learning_rate': 0.11083115186299362}. Best is trial 59 with value: 0.7464.\n",
            "[I 2024-08-07 03:57:24,559] Trial 147 finished with value: 0.7256 and parameters: {'n_estimators': 189, 'max_depth': 10, 'learning_rate': 0.07253487057859824}. Best is trial 59 with value: 0.7464.\n",
            "[I 2024-08-07 03:58:31,677] Trial 148 finished with value: 0.7336 and parameters: {'n_estimators': 172, 'max_depth': 26, 'learning_rate': 0.09357517123447612}. Best is trial 59 with value: 0.7464.\n",
            "[I 2024-08-07 03:59:01,099] Trial 149 finished with value: 0.7232 and parameters: {'n_estimators': 130, 'max_depth': 7, 'learning_rate': 0.08298889759828738}. Best is trial 59 with value: 0.7464.\n",
            "[I 2024-08-07 03:59:48,138] Trial 150 finished with value: 0.72 and parameters: {'n_estimators': 166, 'max_depth': 37, 'learning_rate': 0.16637317377068395}. Best is trial 59 with value: 0.7464.\n",
            "[I 2024-08-07 04:00:41,686] Trial 151 finished with value: 0.7312 and parameters: {'n_estimators': 162, 'max_depth': 17, 'learning_rate': 0.12803011882518708}. Best is trial 59 with value: 0.7464.\n",
            "[I 2024-08-07 04:01:32,772] Trial 152 finished with value: 0.7272 and parameters: {'n_estimators': 169, 'max_depth': 18, 'learning_rate': 0.14299957163075283}. Best is trial 59 with value: 0.7464.\n",
            "[I 2024-08-07 04:02:32,510] Trial 153 finished with value: 0.7368 and parameters: {'n_estimators': 181, 'max_depth': 16, 'learning_rate': 0.11527502255723937}. Best is trial 59 with value: 0.7464.\n",
            "[I 2024-08-07 04:03:32,364] Trial 154 finished with value: 0.7312 and parameters: {'n_estimators': 181, 'max_depth': 23, 'learning_rate': 0.11692504926041464}. Best is trial 59 with value: 0.7464.\n",
            "[I 2024-08-07 04:04:35,018] Trial 155 finished with value: 0.736 and parameters: {'n_estimators': 187, 'max_depth': 16, 'learning_rate': 0.10865937540755545}. Best is trial 59 with value: 0.7464.\n",
            "[I 2024-08-07 04:05:25,412] Trial 156 finished with value: 0.7296 and parameters: {'n_estimators': 175, 'max_depth': 9, 'learning_rate': 0.10005970568322345}. Best is trial 59 with value: 0.7464.\n",
            "[I 2024-08-07 04:06:13,816] Trial 157 finished with value: 0.7128 and parameters: {'n_estimators': 58, 'max_depth': 19, 'learning_rate': 0.057810544258833196}. Best is trial 59 with value: 0.7464.\n",
            "[I 2024-08-07 04:07:25,139] Trial 158 finished with value: 0.7216 and parameters: {'n_estimators': 183, 'max_depth': 21, 'learning_rate': 0.08734467036975481}. Best is trial 59 with value: 0.7464.\n",
            "[I 2024-08-07 04:08:07,189] Trial 159 finished with value: 0.7232 and parameters: {'n_estimators': 180, 'max_depth': 8, 'learning_rate': 0.11778879235847721}. Best is trial 59 with value: 0.7464.\n",
            "[I 2024-08-07 04:08:58,525] Trial 160 finished with value: 0.7384 and parameters: {'n_estimators': 173, 'max_depth': 11, 'learning_rate': 0.1263628134742943}. Best is trial 59 with value: 0.7464.\n",
            "[I 2024-08-07 04:09:49,271] Trial 161 finished with value: 0.736 and parameters: {'n_estimators': 172, 'max_depth': 12, 'learning_rate': 0.1350702073214554}. Best is trial 59 with value: 0.7464.\n",
            "[I 2024-08-07 04:10:40,339] Trial 162 finished with value: 0.7248 and parameters: {'n_estimators': 178, 'max_depth': 11, 'learning_rate': 0.12747942769106352}. Best is trial 59 with value: 0.7464.\n",
            "[I 2024-08-07 04:11:30,864] Trial 163 finished with value: 0.7296 and parameters: {'n_estimators': 168, 'max_depth': 10, 'learning_rate': 0.11366783103590326}. Best is trial 59 with value: 0.7464.\n",
            "[I 2024-08-07 04:12:21,011] Trial 164 finished with value: 0.7376 and parameters: {'n_estimators': 185, 'max_depth': 9, 'learning_rate': 0.10773525930122639}. Best is trial 59 with value: 0.7464.\n",
            "[I 2024-08-07 04:13:12,064] Trial 165 finished with value: 0.7336 and parameters: {'n_estimators': 185, 'max_depth': 9, 'learning_rate': 0.10263090108581346}. Best is trial 59 with value: 0.7464.\n",
            "[I 2024-08-07 04:13:59,692] Trial 166 finished with value: 0.7248 and parameters: {'n_estimators': 191, 'max_depth': 8, 'learning_rate': 0.09214509277556977}. Best is trial 59 with value: 0.7464.\n",
            "[I 2024-08-07 04:14:49,587] Trial 167 finished with value: 0.724 and parameters: {'n_estimators': 197, 'max_depth': 9, 'learning_rate': 0.12234719511642816}. Best is trial 59 with value: 0.7464.\n",
            "[I 2024-08-07 04:15:46,161] Trial 168 finished with value: 0.74 and parameters: {'n_estimators': 174, 'max_depth': 11, 'learning_rate': 0.1059382794838005}. Best is trial 59 with value: 0.7464.\n",
            "[I 2024-08-07 04:16:30,351] Trial 169 finished with value: 0.736 and parameters: {'n_estimators': 164, 'max_depth': 11, 'learning_rate': 0.15753597987434584}. Best is trial 59 with value: 0.7464.\n",
            "[I 2024-08-07 04:17:29,585] Trial 170 finished with value: 0.7312 and parameters: {'n_estimators': 172, 'max_depth': 13, 'learning_rate': 0.10672517841683911}. Best is trial 59 with value: 0.7464.\n",
            "[I 2024-08-07 04:18:24,926] Trial 171 finished with value: 0.74 and parameters: {'n_estimators': 175, 'max_depth': 10, 'learning_rate': 0.09946520095548049}. Best is trial 59 with value: 0.7464.\n",
            "[I 2024-08-07 04:19:20,422] Trial 172 finished with value: 0.7336 and parameters: {'n_estimators': 175, 'max_depth': 10, 'learning_rate': 0.09992560066915243}. Best is trial 59 with value: 0.7464.\n",
            "[I 2024-08-07 04:20:15,566] Trial 173 finished with value: 0.732 and parameters: {'n_estimators': 157, 'max_depth': 12, 'learning_rate': 0.10946767577192917}. Best is trial 59 with value: 0.7464.\n",
            "[I 2024-08-07 04:21:06,860] Trial 174 finished with value: 0.7472 and parameters: {'n_estimators': 167, 'max_depth': 11, 'learning_rate': 0.12284237516385096}. Best is trial 174 with value: 0.7472.\n",
            "[I 2024-08-07 04:21:56,070] Trial 175 finished with value: 0.7432 and parameters: {'n_estimators': 166, 'max_depth': 11, 'learning_rate': 0.13046038906686913}. Best is trial 174 with value: 0.7472.\n",
            "[I 2024-08-07 04:22:42,911] Trial 176 finished with value: 0.7376 and parameters: {'n_estimators': 163, 'max_depth': 11, 'learning_rate': 0.1404000598807672}. Best is trial 174 with value: 0.7472.\n",
            "[I 2024-08-07 04:23:33,024] Trial 177 finished with value: 0.7272 and parameters: {'n_estimators': 168, 'max_depth': 11, 'learning_rate': 0.12687230180353387}. Best is trial 174 with value: 0.7472.\n",
            "[I 2024-08-07 04:24:18,096] Trial 178 finished with value: 0.736 and parameters: {'n_estimators': 160, 'max_depth': 10, 'learning_rate': 0.13521714385792172}. Best is trial 174 with value: 0.7472.\n",
            "[I 2024-08-07 04:25:05,417] Trial 179 finished with value: 0.7344 and parameters: {'n_estimators': 165, 'max_depth': 12, 'learning_rate': 0.14773092322564993}. Best is trial 174 with value: 0.7472.\n",
            "[I 2024-08-07 04:26:44,282] Trial 180 finished with value: 0.7296 and parameters: {'n_estimators': 171, 'max_depth': 30, 'learning_rate': 0.046660476820560036}. Best is trial 174 with value: 0.7472.\n",
            "[I 2024-08-07 04:27:37,228] Trial 181 finished with value: 0.7272 and parameters: {'n_estimators': 176, 'max_depth': 10, 'learning_rate': 0.10897740259990546}. Best is trial 174 with value: 0.7472.\n",
            "[I 2024-08-07 04:28:14,509] Trial 182 finished with value: 0.7344 and parameters: {'n_estimators': 99, 'max_depth': 9, 'learning_rate': 0.09700537207638729}. Best is trial 174 with value: 0.7472.\n",
            "[I 2024-08-07 04:28:53,948] Trial 183 finished with value: 0.74 and parameters: {'n_estimators': 167, 'max_depth': 8, 'learning_rate': 0.12236123339018727}. Best is trial 174 with value: 0.7472.\n",
            "[I 2024-08-07 04:29:33,059] Trial 184 finished with value: 0.728 and parameters: {'n_estimators': 167, 'max_depth': 8, 'learning_rate': 0.12653768078483923}. Best is trial 174 with value: 0.7472.\n",
            "[I 2024-08-07 04:30:25,418] Trial 185 finished with value: 0.7408 and parameters: {'n_estimators': 171, 'max_depth': 11, 'learning_rate': 0.12048335512926076}. Best is trial 174 with value: 0.7472.\n",
            "[I 2024-08-07 04:31:17,872] Trial 186 finished with value: 0.736 and parameters: {'n_estimators': 155, 'max_depth': 12, 'learning_rate': 0.11753219058360434}. Best is trial 174 with value: 0.7472.\n",
            "[I 2024-08-07 04:32:08,113] Trial 187 finished with value: 0.716 and parameters: {'n_estimators': 150, 'max_depth': 11, 'learning_rate': 0.11540317039935291}. Best is trial 174 with value: 0.7472.\n",
            "[I 2024-08-07 04:32:44,310] Trial 188 finished with value: 0.7352 and parameters: {'n_estimators': 162, 'max_depth': 13, 'learning_rate': 0.24424086263413944}. Best is trial 174 with value: 0.7472.\n",
            "[I 2024-08-07 04:33:16,035] Trial 189 finished with value: 0.736 and parameters: {'n_estimators': 168, 'max_depth': 7, 'learning_rate': 0.14161013031175676}. Best is trial 174 with value: 0.7472.\n",
            "[I 2024-08-07 04:34:11,002] Trial 190 finished with value: 0.736 and parameters: {'n_estimators': 174, 'max_depth': 10, 'learning_rate': 0.10214412923527963}. Best is trial 174 with value: 0.7472.\n",
            "[I 2024-08-07 04:35:01,185] Trial 191 finished with value: 0.7376 and parameters: {'n_estimators': 171, 'max_depth': 11, 'learning_rate': 0.12829357905948385}. Best is trial 174 with value: 0.7472.\n",
            "[I 2024-08-07 04:35:45,653] Trial 192 finished with value: 0.7328 and parameters: {'n_estimators': 166, 'max_depth': 9, 'learning_rate': 0.12215365801701258}. Best is trial 174 with value: 0.7472.\n",
            "[I 2024-08-07 04:36:37,281] Trial 193 finished with value: 0.7368 and parameters: {'n_estimators': 172, 'max_depth': 12, 'learning_rate': 0.13179985493163301}. Best is trial 174 with value: 0.7472.\n",
            "[I 2024-08-07 04:37:26,692] Trial 194 finished with value: 0.7184 and parameters: {'n_estimators': 159, 'max_depth': 10, 'learning_rate': 0.11256303884554958}. Best is trial 174 with value: 0.7472.\n",
            "[I 2024-08-07 04:37:52,971] Trial 195 finished with value: 0.7368 and parameters: {'n_estimators': 177, 'max_depth': 6, 'learning_rate': 0.12198501195838501}. Best is trial 174 with value: 0.7472.\n",
            "[I 2024-08-07 04:38:29,056] Trial 196 finished with value: 0.7304 and parameters: {'n_estimators': 170, 'max_depth': 8, 'learning_rate': 0.15407808303653375}. Best is trial 174 with value: 0.7472.\n",
            "[I 2024-08-07 04:39:08,026] Trial 197 finished with value: 0.7296 and parameters: {'n_estimators': 90, 'max_depth': 10, 'learning_rate': 0.10355130286640259}. Best is trial 174 with value: 0.7472.\n",
            "[I 2024-08-07 04:40:01,003] Trial 198 finished with value: 0.7296 and parameters: {'n_estimators': 164, 'max_depth': 24, 'learning_rate': 0.1338393658045501}. Best is trial 174 with value: 0.7472.\n",
            "[I 2024-08-07 04:41:01,311] Trial 199 finished with value: 0.7216 and parameters: {'n_estimators': 177, 'max_depth': 11, 'learning_rate': 0.09591510525216367}. Best is trial 174 with value: 0.7472.\n",
            "[I 2024-08-07 04:41:42,521] Trial 200 finished with value: 0.7488 and parameters: {'n_estimators': 173, 'max_depth': 8, 'learning_rate': 0.11424867282836902}. Best is trial 200 with value: 0.7488.\n",
            "[I 2024-08-07 04:42:23,745] Trial 201 finished with value: 0.7344 and parameters: {'n_estimators': 174, 'max_depth': 8, 'learning_rate': 0.11667001666885222}. Best is trial 200 with value: 0.7488.\n",
            "[I 2024-08-07 04:43:11,175] Trial 202 finished with value: 0.7368 and parameters: {'n_estimators': 170, 'max_depth': 9, 'learning_rate': 0.10861003893544677}. Best is trial 200 with value: 0.7488.\n",
            "[I 2024-08-07 04:43:44,026] Trial 203 finished with value: 0.7264 and parameters: {'n_estimators': 166, 'max_depth': 7, 'learning_rate': 0.11900042332298759}. Best is trial 200 with value: 0.7488.\n",
            "[I 2024-08-07 04:44:08,732] Trial 204 finished with value: 0.7216 and parameters: {'n_estimators': 38, 'max_depth': 11, 'learning_rate': 0.1122839050095348}. Best is trial 200 with value: 0.7488.\n",
            "[I 2024-08-07 04:44:48,572] Trial 205 finished with value: 0.7376 and parameters: {'n_estimators': 174, 'max_depth': 8, 'learning_rate': 0.12658760334303754}. Best is trial 200 with value: 0.7488.\n",
            "[I 2024-08-07 04:45:50,892] Trial 206 finished with value: 0.7328 and parameters: {'n_estimators': 161, 'max_depth': 33, 'learning_rate': 0.10095370328811734}. Best is trial 200 with value: 0.7488.\n",
            "[I 2024-08-07 04:46:37,329] Trial 207 finished with value: 0.7336 and parameters: {'n_estimators': 178, 'max_depth': 10, 'learning_rate': 0.1389116931590548}. Best is trial 200 with value: 0.7488.\n",
            "[I 2024-08-07 04:47:26,050] Trial 208 finished with value: 0.74 and parameters: {'n_estimators': 170, 'max_depth': 9, 'learning_rate': 0.10439277211524592}. Best is trial 200 with value: 0.7488.\n",
            "[I 2024-08-07 04:48:17,820] Trial 209 finished with value: 0.7272 and parameters: {'n_estimators': 168, 'max_depth': 9, 'learning_rate': 0.08883488831910351}. Best is trial 200 with value: 0.7488.\n",
            "[I 2024-08-07 04:48:51,784] Trial 210 finished with value: 0.7392 and parameters: {'n_estimators': 163, 'max_depth': 7, 'learning_rate': 0.0973263952836893}. Best is trial 200 with value: 0.7488.\n",
            "[I 2024-08-07 04:49:26,025] Trial 211 finished with value: 0.7192 and parameters: {'n_estimators': 164, 'max_depth': 7, 'learning_rate': 0.09559841539495618}. Best is trial 200 with value: 0.7488.\n",
            "[I 2024-08-07 04:49:58,716] Trial 212 finished with value: 0.7368 and parameters: {'n_estimators': 158, 'max_depth': 7, 'learning_rate': 0.10624842406199826}. Best is trial 200 with value: 0.7488.\n",
            "[I 2024-08-07 04:50:47,450] Trial 213 finished with value: 0.7352 and parameters: {'n_estimators': 169, 'max_depth': 9, 'learning_rate': 0.10214168391047572}. Best is trial 200 with value: 0.7488.\n",
            "[I 2024-08-07 04:51:04,873] Trial 214 finished with value: 0.7432 and parameters: {'n_estimators': 162, 'max_depth': 5, 'learning_rate': 0.20579693136065536}. Best is trial 200 with value: 0.7488.\n",
            "[I 2024-08-07 04:51:21,350] Trial 215 finished with value: 0.732 and parameters: {'n_estimators': 161, 'max_depth': 5, 'learning_rate': 0.22405216701462594}. Best is trial 200 with value: 0.7488.\n",
            "[I 2024-08-07 04:51:38,263] Trial 216 finished with value: 0.7344 and parameters: {'n_estimators': 165, 'max_depth': 5, 'learning_rate': 0.11237164115970694}. Best is trial 200 with value: 0.7488.\n",
            "[I 2024-08-07 04:52:00,396] Trial 217 finished with value: 0.7256 and parameters: {'n_estimators': 157, 'max_depth': 6, 'learning_rate': 0.20423057728863492}. Best is trial 200 with value: 0.7488.\n",
            "[I 2024-08-07 04:52:31,335] Trial 218 finished with value: 0.7272 and parameters: {'n_estimators': 153, 'max_depth': 8, 'learning_rate': 0.188764089141106}. Best is trial 200 with value: 0.7488.\n",
            "[I 2024-08-07 04:52:53,929] Trial 219 finished with value: 0.7192 and parameters: {'n_estimators': 172, 'max_depth': 6, 'learning_rate': 0.2447879511302895}. Best is trial 200 with value: 0.7488.\n",
            "[I 2024-08-07 04:53:42,836] Trial 220 finished with value: 0.7368 and parameters: {'n_estimators': 166, 'max_depth': 10, 'learning_rate': 0.11984786426544289}. Best is trial 200 with value: 0.7488.\n",
            "[I 2024-08-07 04:54:39,515] Trial 221 finished with value: 0.7152 and parameters: {'n_estimators': 162, 'max_depth': 12, 'learning_rate': 0.10744928071137352}. Best is trial 200 with value: 0.7488.\n",
            "[I 2024-08-07 04:55:23,916] Trial 222 finished with value: 0.7416 and parameters: {'n_estimators': 169, 'max_depth': 8, 'learning_rate': 0.09111721495915219}. Best is trial 200 with value: 0.7488.\n",
            "[I 2024-08-07 04:56:00,285] Trial 223 finished with value: 0.74 and parameters: {'n_estimators': 170, 'max_depth': 7, 'learning_rate': 0.08331812759847561}. Best is trial 200 with value: 0.7488.\n",
            "[I 2024-08-07 04:56:36,751] Trial 224 finished with value: 0.7328 and parameters: {'n_estimators': 169, 'max_depth': 7, 'learning_rate': 0.08549378900630217}. Best is trial 200 with value: 0.7488.\n",
            "[I 2024-08-07 04:57:25,104] Trial 225 finished with value: 0.7384 and parameters: {'n_estimators': 178, 'max_depth': 8, 'learning_rate': 0.080556949522678}. Best is trial 200 with value: 0.7488.\n",
            "[I 2024-08-07 04:57:50,701] Trial 226 finished with value: 0.732 and parameters: {'n_estimators': 167, 'max_depth': 6, 'learning_rate': 0.09211198270005992}. Best is trial 200 with value: 0.7488.\n",
            "[I 2024-08-07 04:58:08,362] Trial 227 finished with value: 0.7352 and parameters: {'n_estimators': 76, 'max_depth': 8, 'learning_rate': 0.28424270794456297}. Best is trial 200 with value: 0.7488.\n",
            "[I 2024-08-07 04:58:37,306] Trial 228 finished with value: 0.7304 and parameters: {'n_estimators': 162, 'max_depth': 7, 'learning_rate': 0.17425056642026138}. Best is trial 200 with value: 0.7488.\n",
            "[I 2024-08-07 04:59:33,808] Trial 229 finished with value: 0.7272 and parameters: {'n_estimators': 175, 'max_depth': 9, 'learning_rate': 0.07802799343399906}. Best is trial 200 with value: 0.7488.\n",
            "[I 2024-08-07 05:00:23,442] Trial 230 finished with value: 0.7488 and parameters: {'n_estimators': 169, 'max_depth': 9, 'learning_rate': 0.09808941754372048}. Best is trial 200 with value: 0.7488.\n",
            "[I 2024-08-07 05:01:13,917] Trial 231 finished with value: 0.7384 and parameters: {'n_estimators': 170, 'max_depth': 9, 'learning_rate': 0.09463358902431397}. Best is trial 200 with value: 0.7488.\n",
            "[I 2024-08-07 05:01:58,288] Trial 232 finished with value: 0.7392 and parameters: {'n_estimators': 165, 'max_depth': 8, 'learning_rate': 0.08826383696071925}. Best is trial 200 with value: 0.7488.\n",
            "[I 2024-08-07 05:02:34,147] Trial 233 finished with value: 0.7256 and parameters: {'n_estimators': 166, 'max_depth': 7, 'learning_rate': 0.08459952485499111}. Best is trial 200 with value: 0.7488.\n",
            "[I 2024-08-07 05:03:17,249] Trial 234 finished with value: 0.7272 and parameters: {'n_estimators': 162, 'max_depth': 8, 'learning_rate': 0.09271939206837336}. Best is trial 200 with value: 0.7488.\n",
            "[I 2024-08-07 05:04:08,870] Trial 235 finished with value: 0.7536 and parameters: {'n_estimators': 158, 'max_depth': 9, 'learning_rate': 0.08508346541012761}. Best is trial 235 with value: 0.7536.\n",
            "[I 2024-08-07 05:04:59,372] Trial 236 finished with value: 0.7376 and parameters: {'n_estimators': 157, 'max_depth': 9, 'learning_rate': 0.08739860116786756}. Best is trial 235 with value: 0.7536.\n",
            "[I 2024-08-07 05:05:44,811] Trial 237 finished with value: 0.7368 and parameters: {'n_estimators': 164, 'max_depth': 8, 'learning_rate': 0.08021594016845424}. Best is trial 235 with value: 0.7536.\n",
            "[I 2024-08-07 05:06:20,244] Trial 238 finished with value: 0.7224 and parameters: {'n_estimators': 160, 'max_depth': 7, 'learning_rate': 0.07686338583671978}. Best is trial 235 with value: 0.7536.\n",
            "[I 2024-08-07 05:06:46,747] Trial 239 finished with value: 0.7304 and parameters: {'n_estimators': 169, 'max_depth': 6, 'learning_rate': 0.06756510443002847}. Best is trial 235 with value: 0.7536.\n",
            "[I 2024-08-07 05:07:47,831] Trial 240 finished with value: 0.7304 and parameters: {'n_estimators': 155, 'max_depth': 10, 'learning_rate': 0.07158529350575747}. Best is trial 235 with value: 0.7536.\n",
            "[I 2024-08-07 05:08:37,162] Trial 241 finished with value: 0.724 and parameters: {'n_estimators': 166, 'max_depth': 9, 'learning_rate': 0.09831654295219597}. Best is trial 235 with value: 0.7536.\n",
            "[I 2024-08-07 05:09:34,261] Trial 242 finished with value: 0.7376 and parameters: {'n_estimators': 170, 'max_depth': 10, 'learning_rate': 0.09052857917188066}. Best is trial 235 with value: 0.7536.\n",
            "[I 2024-08-07 05:10:20,548] Trial 243 finished with value: 0.7224 and parameters: {'n_estimators': 174, 'max_depth': 8, 'learning_rate': 0.08459794927845035}. Best is trial 235 with value: 0.7536.\n",
            "[I 2024-08-07 05:11:02,796] Trial 244 finished with value: 0.7264 and parameters: {'n_estimators': 164, 'max_depth': 8, 'learning_rate': 0.10037738293017186}. Best is trial 235 with value: 0.7536.\n",
            "[I 2024-08-07 05:11:57,950] Trial 245 finished with value: 0.736 and parameters: {'n_estimators': 172, 'max_depth': 10, 'learning_rate': 0.09752558370102714}. Best is trial 235 with value: 0.7536.\n",
            "[I 2024-08-07 05:12:45,952] Trial 246 finished with value: 0.7304 and parameters: {'n_estimators': 168, 'max_depth': 9, 'learning_rate': 0.10567768062450077}. Best is trial 235 with value: 0.7536.\n",
            "[I 2024-08-07 05:13:49,131] Trial 247 finished with value: 0.7216 and parameters: {'n_estimators': 179, 'max_depth': 11, 'learning_rate': 0.08921793094865507}. Best is trial 235 with value: 0.7536.\n",
            "[I 2024-08-07 05:14:48,220] Trial 248 finished with value: 0.7216 and parameters: {'n_estimators': 159, 'max_depth': 28, 'learning_rate': 0.11049432928616547}. Best is trial 235 with value: 0.7536.\n",
            "[I 2024-08-07 05:15:22,623] Trial 249 finished with value: 0.736 and parameters: {'n_estimators': 174, 'max_depth': 7, 'learning_rate': 0.11440558432483774}. Best is trial 235 with value: 0.7536.\n",
            "[I 2024-08-07 05:15:39,610] Trial 250 finished with value: 0.724 and parameters: {'n_estimators': 164, 'max_depth': 5, 'learning_rate': 0.09489798456456107}. Best is trial 235 with value: 0.7536.\n",
            "[I 2024-08-07 05:16:28,316] Trial 251 finished with value: 0.7264 and parameters: {'n_estimators': 170, 'max_depth': 9, 'learning_rate': 0.10312580107451928}. Best is trial 235 with value: 0.7536.\n",
            "[I 2024-08-07 05:17:18,478] Trial 252 finished with value: 0.7336 and parameters: {'n_estimators': 176, 'max_depth': 10, 'learning_rate': 0.119082953602311}. Best is trial 235 with value: 0.7536.\n",
            "[I 2024-08-07 05:18:02,084] Trial 253 finished with value: 0.7272 and parameters: {'n_estimators': 160, 'max_depth': 8, 'learning_rate': 0.08667213518309688}. Best is trial 235 with value: 0.7536.\n",
            "[I 2024-08-07 05:18:27,397] Trial 254 finished with value: 0.7336 and parameters: {'n_estimators': 167, 'max_depth': 6, 'learning_rate': 0.10420980521851246}. Best is trial 235 with value: 0.7536.\n",
            "[I 2024-08-07 05:19:12,113] Trial 255 finished with value: 0.7352 and parameters: {'n_estimators': 179, 'max_depth': 9, 'learning_rate': 0.13324061626912315}. Best is trial 235 with value: 0.7536.\n",
            "[I 2024-08-07 05:20:02,620] Trial 256 finished with value: 0.728 and parameters: {'n_estimators': 163, 'max_depth': 10, 'learning_rate': 0.11176110082064754}. Best is trial 235 with value: 0.7536.\n",
            "[I 2024-08-07 05:20:30,604] Trial 257 finished with value: 0.7376 and parameters: {'n_estimators': 172, 'max_depth': 7, 'learning_rate': 0.21044513138048207}. Best is trial 235 with value: 0.7536.\n",
            "[I 2024-08-07 05:21:11,076] Trial 258 finished with value: 0.7336 and parameters: {'n_estimators': 152, 'max_depth': 8, 'learning_rate': 0.09736903140733083}. Best is trial 235 with value: 0.7536.\n",
            "[I 2024-08-07 05:22:47,147] Trial 259 finished with value: 0.7232 and parameters: {'n_estimators': 168, 'max_depth': 11, 'learning_rate': 0.03456000573370139}. Best is trial 235 with value: 0.7536.\n",
            "[I 2024-08-07 05:23:36,974] Trial 260 finished with value: 0.724 and parameters: {'n_estimators': 146, 'max_depth': 9, 'learning_rate': 0.08172851782774636}. Best is trial 235 with value: 0.7536.\n",
            "[I 2024-08-07 05:24:27,095] Trial 261 finished with value: 0.7384 and parameters: {'n_estimators': 158, 'max_depth': 11, 'learning_rate': 0.12186142601652644}. Best is trial 235 with value: 0.7536.\n",
            "[I 2024-08-07 05:25:02,022] Trial 262 finished with value: 0.7256 and parameters: {'n_estimators': 165, 'max_depth': 7, 'learning_rate': 0.09143564323815315}. Best is trial 235 with value: 0.7536.\n",
            "[I 2024-08-07 05:25:34,405] Trial 263 finished with value: 0.7304 and parameters: {'n_estimators': 182, 'max_depth': 9, 'learning_rate': 0.25541146317078983}. Best is trial 235 with value: 0.7536.\n",
            "[I 2024-08-07 05:25:56,472] Trial 264 finished with value: 0.7224 and parameters: {'n_estimators': 175, 'max_depth': 6, 'learning_rate': 0.29367371457526187}. Best is trial 235 with value: 0.7536.\n",
            "[I 2024-08-07 05:27:06,991] Trial 265 finished with value: 0.7328 and parameters: {'n_estimators': 172, 'max_depth': 12, 'learning_rate': 0.07555500015240575}. Best is trial 235 with value: 0.7536.\n",
            "[I 2024-08-07 05:27:57,352] Trial 266 finished with value: 0.7384 and parameters: {'n_estimators': 163, 'max_depth': 27, 'learning_rate': 0.14532725923628437}. Best is trial 235 with value: 0.7536.\n",
            "[I 2024-08-07 05:28:48,866] Trial 267 finished with value: 0.7336 and parameters: {'n_estimators': 168, 'max_depth': 10, 'learning_rate': 0.10829935573995149}. Best is trial 235 with value: 0.7536.\n",
            "[I 2024-08-07 05:29:30,394] Trial 268 finished with value: 0.7336 and parameters: {'n_estimators': 176, 'max_depth': 8, 'learning_rate': 0.11663189264725918}. Best is trial 235 with value: 0.7536.\n",
            "[I 2024-08-07 05:30:25,042] Trial 269 finished with value: 0.7328 and parameters: {'n_estimators': 170, 'max_depth': 31, 'learning_rate': 0.1297817531307194}. Best is trial 235 with value: 0.7536.\n",
            "[I 2024-08-07 05:31:17,857] Trial 270 finished with value: 0.7368 and parameters: {'n_estimators': 161, 'max_depth': 10, 'learning_rate': 0.1015776181346355}. Best is trial 235 with value: 0.7536.\n",
            "[I 2024-08-07 05:31:59,357] Trial 271 finished with value: 0.7264 and parameters: {'n_estimators': 155, 'max_depth': 8, 'learning_rate': 0.09389713880758632}. Best is trial 235 with value: 0.7536.\n",
            "[I 2024-08-07 05:33:10,693] Trial 272 finished with value: 0.7288 and parameters: {'n_estimators': 180, 'max_depth': 15, 'learning_rate': 0.0839863978928161}. Best is trial 235 with value: 0.7536.\n",
            "[I 2024-08-07 05:33:17,865] Trial 273 finished with value: 0.7408 and parameters: {'n_estimators': 66, 'max_depth': 5, 'learning_rate': 0.11223054876461099}. Best is trial 235 with value: 0.7536.\n",
            "[I 2024-08-07 05:33:25,355] Trial 274 finished with value: 0.7192 and parameters: {'n_estimators': 70, 'max_depth': 5, 'learning_rate': 0.12321054461843102}. Best is trial 235 with value: 0.7536.\n",
            "[I 2024-08-07 05:33:28,385] Trial 275 finished with value: 0.7072 and parameters: {'n_estimators': 25, 'max_depth': 5, 'learning_rate': 0.11238400036126878}. Best is trial 235 with value: 0.7536.\n",
            "[I 2024-08-07 05:33:38,752] Trial 276 finished with value: 0.732 and parameters: {'n_estimators': 61, 'max_depth': 6, 'learning_rate': 0.10259868301466797}. Best is trial 235 with value: 0.7536.\n",
            "[I 2024-08-07 05:34:43,627] Trial 277 finished with value: 0.7216 and parameters: {'n_estimators': 165, 'max_depth': 13, 'learning_rate': 0.0893300850411251}. Best is trial 235 with value: 0.7536.\n",
            "[I 2024-08-07 05:35:01,177] Trial 278 finished with value: 0.7248 and parameters: {'n_estimators': 173, 'max_depth': 5, 'learning_rate': 0.13129736838762357}. Best is trial 235 with value: 0.7536.\n",
            "[I 2024-08-07 05:36:08,660] Trial 279 finished with value: 0.7432 and parameters: {'n_estimators': 184, 'max_depth': 29, 'learning_rate': 0.09700064026359476}. Best is trial 235 with value: 0.7536.\n",
            "[I 2024-08-07 05:36:55,156] Trial 280 finished with value: 0.7216 and parameters: {'n_estimators': 88, 'max_depth': 30, 'learning_rate': 0.10742624674839969}. Best is trial 235 with value: 0.7536.\n",
            "[I 2024-08-07 05:37:21,507] Trial 281 finished with value: 0.7488 and parameters: {'n_estimators': 185, 'max_depth': 6, 'learning_rate': 0.15824099294136032}. Best is trial 235 with value: 0.7536.\n",
            "[I 2024-08-07 05:38:10,094] Trial 282 finished with value: 0.7208 and parameters: {'n_estimators': 188, 'max_depth': 29, 'learning_rate': 0.1689016343907754}. Best is trial 235 with value: 0.7536.\n",
            "[I 2024-08-07 05:38:46,485] Trial 283 finished with value: 0.7232 and parameters: {'n_estimators': 82, 'max_depth': 31, 'learning_rate': 0.1593348717527616}. Best is trial 235 with value: 0.7536.\n",
            "[I 2024-08-07 05:39:17,793] Trial 284 finished with value: 0.7144 and parameters: {'n_estimators': 52, 'max_depth': 28, 'learning_rate': 0.14914863794330377}. Best is trial 235 with value: 0.7536.\n",
            "[I 2024-08-07 05:39:19,788] Trial 285 finished with value: 0.6816 and parameters: {'n_estimators': 10, 'max_depth': 6, 'learning_rate': 0.13369026779487614}. Best is trial 235 with value: 0.7536.\n",
            "[I 2024-08-07 05:40:05,771] Trial 286 finished with value: 0.7344 and parameters: {'n_estimators': 186, 'max_depth': 30, 'learning_rate': 0.18326367715153644}. Best is trial 235 with value: 0.7536.\n",
            "[I 2024-08-07 05:40:59,847] Trial 287 finished with value: 0.7304 and parameters: {'n_estimators': 182, 'max_depth': 29, 'learning_rate': 0.1376923322119678}. Best is trial 235 with value: 0.7536.\n",
            "[I 2024-08-07 05:41:19,467] Trial 288 finished with value: 0.724 and parameters: {'n_estimators': 190, 'max_depth': 5, 'learning_rate': 0.14652191471248638}. Best is trial 235 with value: 0.7536.\n",
            "[I 2024-08-07 05:42:55,308] Trial 289 finished with value: 0.7352 and parameters: {'n_estimators': 180, 'max_depth': 26, 'learning_rate': 0.051256566925958036}. Best is trial 235 with value: 0.7536.\n",
            "[I 2024-08-07 05:43:19,766] Trial 290 finished with value: 0.7248 and parameters: {'n_estimators': 186, 'max_depth': 6, 'learning_rate': 0.22364521263808146}. Best is trial 235 with value: 0.7536.\n",
            "[I 2024-08-07 05:44:19,777] Trial 291 finished with value: 0.7304 and parameters: {'n_estimators': 185, 'max_depth': 20, 'learning_rate': 0.11695777480382191}. Best is trial 235 with value: 0.7536.\n",
            "[I 2024-08-07 05:44:53,869] Trial 292 finished with value: 0.7304 and parameters: {'n_estimators': 177, 'max_depth': 7, 'learning_rate': 0.1227594727057641}. Best is trial 235 with value: 0.7536.\n",
            "[I 2024-08-07 05:45:16,165] Trial 293 finished with value: 0.7208 and parameters: {'n_estimators': 39, 'max_depth': 11, 'learning_rate': 0.15435493764248984}. Best is trial 235 with value: 0.7536.\n",
            "[I 2024-08-07 05:46:17,096] Trial 294 finished with value: 0.7336 and parameters: {'n_estimators': 183, 'max_depth': 34, 'learning_rate': 0.11291632183180335}. Best is trial 235 with value: 0.7536.\n",
            "[I 2024-08-07 05:46:36,555] Trial 295 finished with value: 0.732 and parameters: {'n_estimators': 192, 'max_depth': 5, 'learning_rate': 0.14112069866736093}. Best is trial 235 with value: 0.7536.\n",
            "[I 2024-08-07 05:47:33,035] Trial 296 finished with value: 0.7328 and parameters: {'n_estimators': 178, 'max_depth': 28, 'learning_rate': 0.12670415142209673}. Best is trial 235 with value: 0.7536.\n",
            "[I 2024-08-07 05:50:14,333] Trial 297 finished with value: 0.7128 and parameters: {'n_estimators': 175, 'max_depth': 18, 'learning_rate': 0.011654645049565175}. Best is trial 235 with value: 0.7536.\n",
            "[I 2024-08-07 05:51:31,799] Trial 298 finished with value: 0.7296 and parameters: {'n_estimators': 182, 'max_depth': 11, 'learning_rate': 0.06346979908558745}. Best is trial 235 with value: 0.7536.\n",
            "[I 2024-08-07 05:52:20,679] Trial 299 finished with value: 0.7216 and parameters: {'n_estimators': 171, 'max_depth': 9, 'learning_rate': 0.10338304278990573}. Best is trial 235 with value: 0.7536.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Melhor solução:\n",
            "Valor: 0.7536\n",
            "Parâmetros: \n",
            "    n_estimators: 158\n",
            "    max_depth: 9\n",
            "    learning_rate: 0.08508346541012761\n"
          ]
        }
      ],
      "source": [
        "import optuna\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Codificar os rótulos\n",
        "label_encoder = LabelEncoder()\n",
        "y_train_encoded = label_encoder.fit_transform(y_train)\n",
        "y_test_encoded = label_encoder.transform(y_test)\n",
        "\n",
        "# Variáveis para armazenar o melhor modelo e a melhor métrica\n",
        "best_model = None\n",
        "best_accuracy = 0.0\n",
        "\n",
        "def objective(trial):\n",
        "    # Definir o espaço de busca para os hiperparâmetros\n",
        "    n_estimators = trial.suggest_int('n_estimators', 10, 200)\n",
        "    max_depth = trial.suggest_int('max_depth', 5, 40)\n",
        "    learning_rate = trial.suggest_float('learning_rate', 0.01, 0.3, log=True)\n",
        "\n",
        "\n",
        "    # Cria modelo\n",
        "    model = XGBClassifier(\n",
        "        n_estimators=n_estimators,\n",
        "        max_depth=max_depth,\n",
        "        learning_rate=learning_rate\n",
        "    )\n",
        "\n",
        "    model.fit(X_train_concat, y_train_encoded)  # Treina\n",
        "    y_pred = model.predict(X_test_concat)  # Infere\n",
        "    accuracy = accuracy_score(y_test_encoded, y_pred)  # Calcula métrica\n",
        "\n",
        "    # Atualize o melhor modelo se necessário\n",
        "    global best_model, best_accuracy\n",
        "    if accuracy > best_accuracy:\n",
        "        best_model = model\n",
        "        best_accuracy = accuracy\n",
        "\n",
        "    return accuracy\n",
        "\n",
        "# Cria estudo a ser otimizado\n",
        "study = optuna.create_study(direction='maximize')\n",
        "study.optimize(objective, n_trials=300)\n",
        "\n",
        "# Imprime a evolução dos modelos ao final da otimização\n",
        "print(f'Melhor solução:')\n",
        "trial = study.best_trial\n",
        "\n",
        "print(f'Valor: {trial.value}')\n",
        "print(f'Parâmetros: ')\n",
        "for key, value in trial.params.items():\n",
        "    print(f'    {key}: {value}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>cat</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>dog</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>dog</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>dog</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>cat</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id label\n",
              "0   1   cat\n",
              "1   2   dog\n",
              "2   3   dog\n",
              "3   4   dog\n",
              "4   5   cat"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_pred = model.predict(X_submission_concat)\n",
        "\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "\n",
        "results = pd.DataFrame()\n",
        "results['id'] = list(range(1, y_pred.shape[0] + 1))\n",
        "results['label'] = y_pred\n",
        "results.head()\n",
        "\n",
        "# Generate the current timestamp\n",
        "timestamp = datetime.now().strftime('%Y-%m-%d_%H-%M')\n",
        "\n",
        "# Generate the file name with the timestamp\n",
        "file_name = f'results_{timestamp}.csv'\n",
        "\n",
        "# Save the DataFrame to a CSV file\n",
        "results.to_csv(file_name, index=False)\n",
        "\n",
        "# Display the first few rows of the DataFrame\n",
        "results.head()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "databundleVersionId": 9158065,
          "sourceId": 82985,
          "sourceType": "competition"
        }
      ],
      "dockerImageVersionId": 30746,
      "isGpuEnabled": false,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
